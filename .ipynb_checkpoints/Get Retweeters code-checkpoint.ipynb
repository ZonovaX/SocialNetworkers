{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "bearer_token = #copy bearer_token here\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers, params):\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "    print(response.status_code)\n",
    "    while(response.status_code == 429):\n",
    "        time.sleep(6000)\n",
    "        print(response.status_code)\n",
    "        response = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    #print(response.text)\n",
    "    return response.json()\n",
    "\n",
    "def get_retweeters(id):#takes id of a twitter post\n",
    "    tweet_search_url = \"https://api.twitter.com/2/tweets/{}\".format(id)\n",
    "    headers = create_headers(bearer_token)\n",
    "    main_tweet_query_params = {'tweet.fields': 'created_at,author_id'}\n",
    "    main_tweet_json = connect_to_endpoint(tweet_search_url, headers, main_tweet_query_params)\n",
    "    main_tweet_text = main_tweet_json['data']['text']\n",
    "    main_tweet_author = main_tweet_json['data']['author_id']\n",
    "    \n",
    "    retweeters_id = []\n",
    "    all_search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "    retweeters_query_params = {'query': '\\\"{}\\\" retweets_of:{}'.format(main_tweet_text,main_tweet_author),'tweet.fields': 'author_id,created_at,public_metrics', 'max_results': '499', 'start_time': '2012-01-01T23:00:00Z'}\n",
    "    retweeters_json = connect_to_endpoint(all_search_url, headers, retweeters_query_params)\n",
    "    retweeters_id.append([tweet['author_id'] for tweet in retweeters_json['data']])\n",
    "    time.sleep(4)\n",
    "    while len(retweeters_json['meta']) > 3:\n",
    "        retweeters_query_params = {'query': '\\\"{}\\\" retweets_of:{}'.format(main_tweet_text,main_tweet_author),'tweet.fields': 'author_id,created_at,public_metrics', 'max_results': '499', 'start_time': '2012-01-01T23:00:00Z', 'next_token': '{}'.format(retweeters_json['meta']['next_token'])}\n",
    "        retweeters_json = connect_to_endpoint(all_search_url, headers, retweeters_query_params)\n",
    "        retweeters_id.append([tweet['author_id'] for tweet in retweeters_json['data']])\n",
    "        time.sleep(4)\n",
    "    flattened_retweeters_id = [id for page in retweeters_id for id in page]\n",
    "    return flattened_retweeters_id\n",
    "\n",
    "def follow_date(retweeter_id, figure_id): #gives date that retweeteter had retweeted the figure \"minretweets\" number of times\n",
    "    all_search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "    headers = create_headers(bearer_token)\n",
    "    \n",
    "    retweet_count = 0\n",
    "    end_year = 2013\n",
    "    min_retweets = 3 #consider them as starting following the figure after 3 retweets\n",
    "    date = ''\n",
    "    while retweet_count < min_retweets: \n",
    "        retweeters_query_params = {'query': 'retweets_of:{} from:{}'.format(figure_id,retweeter_id),'tweet.fields': 'author_id,created_at,public_metrics', 'max_results': '400', 'start_time': '2012-01-01T23:00:00Z', 'end_time': '{}-01-01T23:00:00Z'.format(str(end_year))}\n",
    "        retweeters_json = connect_to_endpoint(all_search_url, headers, retweeters_query_params)\n",
    "        if retweeters_json['meta']['result_count'] > 0:\n",
    "            retweet_count = retweeters_json['meta']['result_count']\n",
    "            date = retweeters_json['data'][-3]['created_at']\n",
    "            while len(retweeters_json['meta']) > 3: #paginating, running until the last page of retweets\n",
    "                retweeters_query_params = {'query': 'retweets_of:{} from:{}'.format(figure_id,retweeter_id),'tweet.fields': 'author_id,created_at,public_metrics', 'max_results': '400', 'start_time': '2012-01-01T23:00:00Z', 'end_time': '{}-01-01T23:00:00Z'.format(str(end_year)), 'next_token': '{}'.format(retweeters_json['meta']['next_token'])}\n",
    "                retweeters_json = connect_to_endpoint(all_search_url, headers, retweeters_query_params)\n",
    "                date = retweeters_json['data'][-3]['created_at']\n",
    "                time.sleep(4)\n",
    "        else: #if there are no results for a range of years, increase range of years by 1\n",
    "            end_year = end_year + 1\n",
    "            \n",
    "        time.sleep(4)\n",
    "    return date\n",
    "\n",
    "def get_monthly_tweets_list(user_id,full_date):\n",
    "    all_search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "    headers = create_headers(bearer_token)\n",
    "    all_tweets = []\n",
    "    num_Months_Before = 3\n",
    "    num_Months_After = 6\n",
    "    \n",
    "    for month in range(-1*num_Months_Before,num_Months_After):\n",
    "        full_beginning_date_list = list(full_date)\n",
    "        full_ending_date_list = list(full_date)\n",
    "        extracted_date = full_date[0:10]\n",
    "        \n",
    "        beginning_date = (date.fromisoformat(extracted_date) + relativedelta(months=month)).isoformat()\n",
    "        full_beginning_date_list[0:10] = list(beginning_date)\n",
    "        full_beginning_date_str = \"\".join(full_beginning_date_list)\n",
    "        \n",
    "        ending_date = (date.fromisoformat(extracted_date) + relativedelta(months=month+1)).isoformat()\n",
    "        full_ending_date_list[0:10] = list(ending_date)\n",
    "        full_ending_date_str = \"\".join(full_ending_date_list)\n",
    "        \n",
    "        retweeters_query_params = {'query': 'from:{}'.format(user_id),'tweet.fields': 'author_id,created_at,public_metrics', 'max_results': '499', 'start_time': '{}'.format(full_beginning_date_str), 'end_time': '{}'.format(full_ending_date_str)}\n",
    "        retweeters_json = connect_to_endpoint(all_search_url, headers, retweeters_query_params)\n",
    "        months_tweets = []\n",
    "        months_tweets.append(retweeters_json['data'])\n",
    "        time.sleep(4)\n",
    "        while len(retweeters_json['meta']) > 3:\n",
    "            retweeters_query_params = {'query': 'from:{}'.format(user_id),'tweet.fields': 'author_id,created_at,public_metrics', 'max_results': '499', 'start_time': '{}'.format(full_beginning_date_str), 'end_time': '{}'.format(full_ending_date_str), 'next_token': '{}'.format(retweeters_json['meta']['next_token'])}\n",
    "            retweeters_json = connect_to_endpoint(all_search_url, headers, retweeters_query_params)\n",
    "            months_tweets.append(retweeters_json['data'])\n",
    "            time.sleep(4)\n",
    "        monthly_tweets_flat = [tweets for page in months_tweets for tweets in page]\n",
    "        all_tweets.append(monthly_tweets_flat)\n",
    "        time.sleep(4)\n",
    "        \n",
    "    return all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TL_tweet_id: '1023287366352396288'\n",
    "TL_retweeters = get_retweeters(TL_tweet_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
