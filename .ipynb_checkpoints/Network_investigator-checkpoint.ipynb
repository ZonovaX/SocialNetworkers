{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58806a4b",
   "metadata": {},
   "source": [
    "# Use this on a Twitter account to find bad eggs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac5f347",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92907690",
   "metadata": {},
   "source": [
    "### Import these packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9241aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tweepy\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57688b96",
   "metadata": {},
   "source": [
    "### Choose your parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a3a822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Screen name of network's center\n",
    "center = 'erdosinstitute'\n",
    "# Name to save files to\n",
    "name = 'Test'\n",
    "# Number of mutuals to find\n",
    "breadth = 2\n",
    "# Number of times to find them\n",
    "depth = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be4f35e",
   "metadata": {},
   "source": [
    "### Choose your senitment analyzer. For example here we use Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f4f5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Ysgard\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Necessary parts of the analyzer\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# The analyzer itself\n",
    "def analyzer(tweet):\n",
    "    return SentimentIntensityAnalyzer().polarity_scores(tweet)['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc5e8e",
   "metadata": {},
   "source": [
    "### You'll need a Twitter developer account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dffcd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your credentials\n",
    "API_key = ''\n",
    "API_secret_key = ''\n",
    "access_token = ''\n",
    "access_token_secret = ''\n",
    "\n",
    "# Connect to the API\n",
    "authenticator = tweepy.OAuthHandler(API_key, API_secret_key)\n",
    "authenticator.set_access_token(access_token, access_token_secret)\n",
    "API = tweepy.API(authenticator, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f85ec",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5ca3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(user, breadth=10, depth=2, network=[], save=False):\n",
    "    #type user as a screen name so this works\n",
    "    howrite = 'a'\n",
    "    \n",
    "    # Make sure we're finding the right user\n",
    "    if type(user)==str:\n",
    "        user = API.get_user(screen_name=user).id\n",
    "        howrite = 'w'\n",
    "    elif type(user)!=int:\n",
    "        raise Exception(\"Bad user.\")\n",
    "    \n",
    "    #make sure we have good data\n",
    "    try:\n",
    "        friends = API.friends_ids(user_id=user)\n",
    "        friends[0]\n",
    "    except: \n",
    "        return False\n",
    "    \n",
    "    #one list for user's mutuals, one list for everyone\n",
    "    mutuals = []\n",
    "    network.append(user)\n",
    "    if save:\n",
    "        try:\n",
    "            with open(save, howrite) as save_file:\n",
    "                save_file.write(str(user)+'\\n')\n",
    "        except: \n",
    "            raise Exception('Bad save file')\n",
    "    \n",
    "    #we won't delve too deep or too greedily\n",
    "    if depth:\n",
    "        #find random friends of user who follow user back (mutuals)\n",
    "        for friend in np.random.permutation(friends):\n",
    "            friend = int(friend)\n",
    "            if friend not in network:\n",
    "                if API.show_friendship(source_id=friend, target_id=user)[0].following:\n",
    "                    #find their mutuals, but only add them to the list if it's good data\n",
    "                    if build_network(friend, breadth=breadth, depth=depth-1, network=network, save=save):\n",
    "                        #add them to the list\n",
    "                        mutuals.append(friend)\n",
    "                    #but only some of them\n",
    "                    if len(mutuals)==breadth:\n",
    "                        print(friend,'has mutuals',mutuals)\n",
    "                        break\n",
    "    \n",
    "    #and here's the list\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e2c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity(user, count=200):\n",
    "    # Make sure we're finding the right user\n",
    "    if type(user)==str:\n",
    "        apitivity = API.user_timeline(screen_name=user, count=count)\n",
    "    elif type(user)==int:\n",
    "        apitivity = API.user_timeline(user_id=user, count=count)\n",
    "    else:\n",
    "        raise Exception(\"Bad user.\") \n",
    "        \n",
    "    # Make a list of the statuses\n",
    "    activiray = []\n",
    "    #and add the relevant data\n",
    "    for tweet in apitivity:\n",
    "        try: \n",
    "            tweet.retweeted_status\n",
    "            is_retweet = True\n",
    "        except: \n",
    "            is_retweet = False\n",
    "        activiray.append([tweet.text,\n",
    "                         tweet.id,\n",
    "                         is_retweet,\n",
    "                         tweet.is_quote_status,\n",
    "                         type(tweet.in_reply_to_status_id)==int,\n",
    "                         tweet.retweet_count,\n",
    "                         tweet.favorite_count,\n",
    "                         tweet.created_at])\n",
    "        \n",
    "    # turn it into a dataframe\n",
    "    activity = pd.DataFrame(activiray, columns=['Text', 'Id', 'Is_retweet', 'Is_quote', 'Is_reply', 'Retweets', 'Favorites', 'Created'])\n",
    "    \n",
    "    # record the time since the last status update\n",
    "    tsl = [activity.Created[n].to_pydatetime() - activity.Created[n+1].to_pydatetime()\n",
    "                                   for n in range(len(activity)-1)] + [np.nan]\n",
    "    activity['Time_since_last'] = tsl.copy()\n",
    "    \n",
    "    #record how many times in a row the last activity was less than length \n",
    "    for length in streak_lengths:\n",
    "        #record when it was less than length\n",
    "        streak_break = [time>length for time in tsl[:-1]]+[True]\n",
    "        \n",
    "        #intialize beginning of a streak\n",
    "        start = 0\n",
    "        streak = []\n",
    "        for end in range(len(streak_break)):\n",
    "            #if this is the end of a streak,  \n",
    "            if streak_break[end]:\n",
    "                #record it,\n",
    "                streak += [end+1-start for indx in range(end+1-start)]\n",
    "                #and begin the next\n",
    "                start = end+1\n",
    "        \n",
    "        #finally, add it to the data frame\n",
    "        activity['Streak of '+str(length)] = streak\n",
    "        \n",
    "    #record how much activity occured within a given period \n",
    "    for period in per_periods:\n",
    "        per = []\n",
    "        for n in range(len(tsl)):\n",
    "            elapsed = tsl[n]\n",
    "            count, m = 0, 1\n",
    "            #first we look at earlier tweets\n",
    "            while (m+n<len(tsl)) and (elapsed<=period/2):\n",
    "                count += 1\n",
    "                try: elapsed += tsl[m+n]\n",
    "                except: pass\n",
    "                m += 1\n",
    "            m = 0\n",
    "            elapsed = datetime.timedelta(0)\n",
    "            #then later tweets\n",
    "            while n>=m and elapsed<=period/2:\n",
    "                count += 1\n",
    "                m += 1\n",
    "                try: elapsed += tsl[n-m]\n",
    "                except: pass\n",
    "            per += [count]\n",
    "        activity['Per '+str(period)] = per\n",
    "        \n",
    "    return activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8706e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d04fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63adeb29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d3fe82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
