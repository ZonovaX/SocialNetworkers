{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6a4ffed",
   "metadata": {},
   "source": [
    "Standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ad38d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tweepy\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9af40",
   "metadata": {},
   "source": [
    "Text cleaner imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eff1a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ysgard\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "stop_words=stopwords.words('english')\n",
    "punct=string.punctuation\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cf4958",
   "metadata": {},
   "source": [
    "This imports the hedonometer words. Could be used for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "33be7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "hedonometer = pd.read_csv(\"../Hedonometer.csv\")\n",
    "\n",
    "#initialize the categorization\n",
    "negative_words, neutral_words, positive_words, all_words = {}, {}, {}, {}\n",
    "\n",
    "# how clearly valent do we want the words?\n",
    "tolerance = 0\n",
    "\n",
    "# demark words that are clearly negative or positive (neutral is within tolerance standard deviations of 5)\n",
    "for i in hedonometer.index:\n",
    "    score = (hedonometer['Happiness Score'][i]-5)/5\n",
    "    if score+tolerance*hedonometer['Standard Deviation of Ratings'][i]/5<0:\n",
    "        negative_words[hedonometer.Word[i]] = score\n",
    "    elif score-tolerance*hedonometer['Standard Deviation of Ratings'][i]/5>5:\n",
    "        positive_words[hedonometer.Word[i]] = score\n",
    "    else: \n",
    "        neutral_words[hedonometer.Word[i]] = score\n",
    "    all_words[hedonometer.Word[i]] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c98df68",
   "metadata": {},
   "source": [
    "This can save stuff for later usage, in case they're handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "806f0241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_saver(tweets, file='TWagner.csv'):\n",
    "    with open(file, 'a', encoding='utf8') as saveTweets:\n",
    "        for tweet in tweets: \n",
    "            saveTweets.write(str(tweet._json)+'\\n')\n",
    "    \n",
    "def user_saver(user, file='UUagner.csv'):\n",
    "    with open(file, 'a', encoding='utf8') as saveUser:\n",
    "        saveUser.write(str(user)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348b6101",
   "metadata": {},
   "source": [
    "Personal info please don't use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3823f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck = 'QxPH3Ud4nFeHxfiOsnzNr2sql'\n",
    "cs = ''\n",
    "at = '1393253063528431621-Tk8YAgtU3B4SwJa4DmHlhfGlcaiWN6'\n",
    "ats = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff860c5",
   "metadata": {},
   "source": [
    "This creates an instance of the API so that I can pull Tweets from Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f50c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create OAuthHandler object\n",
    "authenticator = tweepy.OAuthHandler(ck, cs)\n",
    "# set access token and secret\n",
    "authenticator.set_access_token(at, ats)\n",
    "# create tweepy API object to fetch tweets\n",
    "API = tweepy.API(authenticator, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6385e63",
   "metadata": {},
   "source": [
    "Practicing/experimenting with followers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f0cd48af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Friendship(_api=<tweepy.api.API object at 0x000001F975D9C588>, _json={'id': 2485562569, 'id_str': '2485562569', 'screen_name': 'DougEpisodes', 'following': False, 'followed_by': True, 'live_following': False, 'following_received': None, 'following_requested': None, 'notifications_enabled': None, 'can_dm': True, 'blocking': None, 'blocked_by': None, 'muting': None, 'want_retweets': None, 'all_replies': None, 'marked_spam': None}, id=2485562569, id_str='2485562569', screen_name='DougEpisodes', following=False, followed_by=True, live_following=False, following_received=None, following_requested=None, notifications_enabled=None, can_dm=True, blocking=None, blocked_by=None, muting=None, want_retweets=None, all_replies=None, marked_spam=None),\n",
       " Friendship(_api=<tweepy.api.API object at 0x000001F975D9C588>, _json={'id': 1015024528337129473, 'id_str': '1015024528337129473', 'screen_name': 'newrockytweets', 'following': True, 'followed_by': False, 'following_received': None, 'following_requested': None}, id=1015024528337129473, id_str='1015024528337129473', screen_name='newrockytweets', following=True, followed_by=False, following_received=None, following_requested=None))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API.show_friendship(source_screen_name='DougEpisodes', target_id=1015024528337129473)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31400b2c",
   "metadata": {},
   "source": [
    "Let's make a dataframe of activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06a7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity(user, count=20, local=False):\n",
    "    # Make sure we're finding the right user\n",
    "    if local:\n",
    "        with open(user, 'r', encoding='utf8') as reader:\n",
    "            pass\n",
    "    elif type(user)==str:\n",
    "        apitivity = API.user_timeline(screen_name=user, count=count)\n",
    "    elif type(user)==int:\n",
    "        apitivity = API.user_timeline(user_id=user, count=count)\n",
    "    else:\n",
    "        raise Exception(\"Bad user.\") \n",
    "        \n",
    "    # Make a list of the statuses\n",
    "    activiray = []\n",
    "    #and add the relevant data\n",
    "    for tweet in apitivity:\n",
    "        try: \n",
    "            tweet.retweeted_status\n",
    "            is_retweet = True\n",
    "        except: \n",
    "            is_retweet = False\n",
    "        activiray.append([tweet.text,\n",
    "                         tweet.id,\n",
    "                         is_retweet,\n",
    "                         tweet.is_quote_status,\n",
    "                         type(tweet.in_reply_to_status_id)==int,\n",
    "                         tweet.retweet_count,\n",
    "                         tweet.favorite_count,\n",
    "                         tweet.created_at])\n",
    "        \n",
    "    # turn it into a dataframe\n",
    "    activi pd.DataFrame(activiray, columns=['Text', 'Id', 'Is_retweet', 'Is_quote', 'Is_reply', 'Retweets', 'Favorites', 'Created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d4068f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_activity(activity, count=20, \n",
    "                   streak_lengths=[datetime.timedelta(minutes=30),datetime.timedelta(hours=6)], \n",
    "                   per_periods=[datetime.timedelta(hours=1),datetime.timedelta(days=1)]):\n",
    "    # Did we already get the activity?\n",
    "    if type(activity)!=pd.core.frame.DataFrame:\n",
    "        activity = get_activity(activity, count=count)\n",
    "    \n",
    "    #clean the text\n",
    "    cleets = []\n",
    "    for twittre in activity.Text:\n",
    "        #this removes mentions\n",
    "        twittre = re.sub(r'@[A-Za-z0-9_]+', '', twittre)\n",
    "        #this removes urls\n",
    "        twittre = re.sub(r'https?:\\/\\/[A-Za-z0-9\\.\\/]+', '', twittre)        \n",
    "        #this removes everything but letters from the str\n",
    "        twittre = re.sub('[^a-zA-Z]',' ',twittre)\n",
    "        #this makes everything lowercase, then turns everything that is separated by a space into its own str\n",
    "        twittre = twittre.lower().split()\n",
    "        #this removes stop words and stems everything else\n",
    "        twittre = [stemmer.stem(word) for word in twittre if (word not in stop_words)]\n",
    "        # this puts it all back together with spaces inbetween\n",
    "        twittre = ' '.join(twittre)\n",
    "        cleets.append(twittre)\n",
    "    activity['Cleaned'] = cleets\n",
    "    \n",
    "    # record the time since the last status update\n",
    "    tsl = [activity.Created[n].to_pydatetime() - activity.Created[n+1].to_pydatetime()\n",
    "                                   for n in range(len(activity)-1)] + [np.nan]\n",
    "    activity['Time_since_last'] = tsl.copy()\n",
    "    \n",
    "    #record how many times in a row the last activity was less than length \n",
    "    for length in streak_lengths:\n",
    "        #record when it was less than length\n",
    "        streak_break = [time>length for time in tsl[:-1]]+[True]\n",
    "        \n",
    "        #intialize beginning of a streak\n",
    "        start = 0\n",
    "        streak = []\n",
    "        for end in range(len(streak_break)):\n",
    "            #if this is the end of a streak,  \n",
    "            if streak_break[end]:\n",
    "                #record it,\n",
    "                streak += [end+1-start for indx in range(end+1-start)]\n",
    "                #and begin the next\n",
    "                start = end+1\n",
    "        \n",
    "        #finally, add it to the data frame\n",
    "        activity['Streak of '+str(length)] = streak\n",
    "        \n",
    "    #record how much activity occured within a given period \n",
    "    for period in per_periods:\n",
    "        per = []\n",
    "        for n in range(len(tsl)):\n",
    "            elapsed = tsl[n]\n",
    "            count, m = 0, 1\n",
    "            #first we look at earlier tweets\n",
    "            while (m+n<len(tsl)) and (elapsed<=period/2):\n",
    "                count += 1\n",
    "                try: elapsed += tsl[m+n]\n",
    "                except: pass\n",
    "                m += 1\n",
    "            m = 0\n",
    "            elapsed = datetime.timedelta(0)\n",
    "            #then later tweets\n",
    "            while n>=m and elapsed<=period/2:\n",
    "                count += 1\n",
    "                m += 1\n",
    "                try: elapsed += tsl[n-m]\n",
    "                except: pass\n",
    "            per += [count]\n",
    "        activity['Per '+str(period)] = per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b8d17c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af1a3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./erdos_core/0.txt', 'r', encoding='utf8') as reader:\n",
    "    tweets = reader.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "7c4e1307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Id</th>\n",
       "      <th>Is_retweet</th>\n",
       "      <th>Is_quote</th>\n",
       "      <th>Is_reply</th>\n",
       "      <th>Reply_of</th>\n",
       "      <th>Replying_to</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Created</th>\n",
       "      <th>Cleaned</th>\n",
       "      <th>Time_since_last</th>\n",
       "      <th>Streak of 1:00:00</th>\n",
       "      <th>Streak of 1 day, 0:00:00</th>\n",
       "      <th>Per 1:00:00</th>\n",
       "      <th>Per 1 day, 0:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @AstronomerPat: @RacineSwick @WorkWithVari ...</td>\n",
       "      <td>1395210702869118982</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-20 02:52:07</td>\n",
       "      <td>rt one week data scienc lectur</td>\n",
       "      <td>2 days 12:09:26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dreams can come true @AstronomerPat https://t....</td>\n",
       "      <td>1394302356267880449</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-17 14:42:41</td>\n",
       "      <td>dream come true</td>\n",
       "      <td>0 days 00:00:38</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@AstronomerPat @WorkWithVari Same excellent co...</td>\n",
       "      <td>1394302197006053379</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.394291e+18</td>\n",
       "      <td>9.130586e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-17 14:42:03</td>\n",
       "      <td>excel content screen</td>\n",
       "      <td>10 days 14:15:05</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Our May Data Science Boot Camp is in full swin...</td>\n",
       "      <td>1390463130627674113</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-05-07 00:26:58</td>\n",
       "      <td>may data scienc boot camp full swing photo credit</td>\n",
       "      <td>0 days 00:09:20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@AstronomerPat @MattOsborne71: This is the mos...</td>\n",
       "      <td>1390460782647906306</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.390296e+18</td>\n",
       "      <td>9.130586e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2021-05-07 00:17:38</td>\n",
       "      <td>retweet ever photo data scienc boot camp</td>\n",
       "      <td>6 days 12:42:47</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @columbusbiz1st: How an OSU math professor ...</td>\n",
       "      <td>1388094491609997320</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-30 11:34:51</td>\n",
       "      <td>rt osu math professor match ph privat sector job</td>\n",
       "      <td>1 days 10:16:08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Our May Data Science Boot Camp with over 350 g...</td>\n",
       "      <td>1387577050735812608</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2021-04-29 01:18:43</td>\n",
       "      <td>may data scienc boot camp grad student postdoc...</td>\n",
       "      <td>6 days 09:23:46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Invitations to Industry continues tonight with...</td>\n",
       "      <td>1385260846515773444</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-22 15:54:57</td>\n",
       "      <td>invit industri continu tonight kenneth maynard...</td>\n",
       "      <td>1 days 16:01:56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @OSUmath: The Hidden Figures course develop...</td>\n",
       "      <td>1384656382406840329</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-20 23:53:01</td>\n",
       "      <td>rt hidden figur cours develop dr ranthoni edmo...</td>\n",
       "      <td>9 days 03:36:50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Invitations to Industry continues Monday 04/12...</td>\n",
       "      <td>1381340320051384321</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-11 20:16:11</td>\n",
       "      <td>invit industri continu monday thoma sznigir st...</td>\n",
       "      <td>8 days 19:50:50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @Schrodinger: Schrödinger’s Chief Biomedica...</td>\n",
       "      <td>1378141537788432384</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-03 00:25:21</td>\n",
       "      <td>rt schr dinger chief biomed scientist karen ak...</td>\n",
       "      <td>1 days 22:16:48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Invitations to Industry continues Thu 04/01 wi...</td>\n",
       "      <td>1377442729899212805</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-04-01 02:08:33</td>\n",
       "      <td>invit industri continu thu senior ux research ...</td>\n",
       "      <td>2 days 12:23:10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Join us for Invitations to Industry tonight wi...</td>\n",
       "      <td>1376530932233076741</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2021-03-29 13:45:23</td>\n",
       "      <td>join us invit industri tonight astronomi phd a...</td>\n",
       "      <td>3 days 21:17:37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Invitations to Industry continues tonight with...</td>\n",
       "      <td>1375122247334166529</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-25 16:27:46</td>\n",
       "      <td>invit industri continu tonight traymon beaver ...</td>\n",
       "      <td>1 days 00:53:03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>May 2021 Boot Camp Participants, Technical Int...</td>\n",
       "      <td>1374746507400859648</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-03-24 15:34:43</td>\n",
       "      <td>may boot camp particip technic interview prep ...</td>\n",
       "      <td>5 days 19:25:24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Join us this evening for Invitations to Indust...</td>\n",
       "      <td>1372641283718664195</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-03-18 20:09:19</td>\n",
       "      <td>join us even invit industri manag advanc analyt</td>\n",
       "      <td>2 days 02:43:34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@EmilyJoGriffith 🚀</td>\n",
       "      <td>1371875346715451401</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.371852e+18</td>\n",
       "      <td>9.233622e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-03-16 17:25:45</td>\n",
       "      <td></td>\n",
       "      <td>1 days 01:14:58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Invitations to Industry continues tonight Marc...</td>\n",
       "      <td>1371494092773994496</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-03-15 16:10:47</td>\n",
       "      <td>invit industri continu tonight march th ana mo...</td>\n",
       "      <td>4 days 19:07:36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@TAMUGradSchool @sigmaxi Thank you for sharing...</td>\n",
       "      <td>1369755736805416961</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.369669e+18</td>\n",
       "      <td>3.867330e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-10 21:03:11</td>\n",
       "      <td>thank share chang zoom link event help prevent u</td>\n",
       "      <td>0 days 01:28:17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RT @TAMUGradSchool: Interested in a career in ...</td>\n",
       "      <td>1369733522815152129</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-10 19:34:54</td>\n",
       "      <td>rt interest career program develop mgmt amp ev...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text                   Id  \\\n",
       "0   RT @AstronomerPat: @RacineSwick @WorkWithVari ...  1395210702869118982   \n",
       "1   Dreams can come true @AstronomerPat https://t....  1394302356267880449   \n",
       "2   @AstronomerPat @WorkWithVari Same excellent co...  1394302197006053379   \n",
       "3   Our May Data Science Boot Camp is in full swin...  1390463130627674113   \n",
       "4   @AstronomerPat @MattOsborne71: This is the mos...  1390460782647906306   \n",
       "5   RT @columbusbiz1st: How an OSU math professor ...  1388094491609997320   \n",
       "6   Our May Data Science Boot Camp with over 350 g...  1387577050735812608   \n",
       "7   Invitations to Industry continues tonight with...  1385260846515773444   \n",
       "8   RT @OSUmath: The Hidden Figures course develop...  1384656382406840329   \n",
       "9   Invitations to Industry continues Monday 04/12...  1381340320051384321   \n",
       "10  RT @Schrodinger: Schrödinger’s Chief Biomedica...  1378141537788432384   \n",
       "11  Invitations to Industry continues Thu 04/01 wi...  1377442729899212805   \n",
       "12  Join us for Invitations to Industry tonight wi...  1376530932233076741   \n",
       "13  Invitations to Industry continues tonight with...  1375122247334166529   \n",
       "14  May 2021 Boot Camp Participants, Technical Int...  1374746507400859648   \n",
       "15  Join us this evening for Invitations to Indust...  1372641283718664195   \n",
       "16                                 @EmilyJoGriffith 🚀  1371875346715451401   \n",
       "17  Invitations to Industry continues tonight Marc...  1371494092773994496   \n",
       "18  @TAMUGradSchool @sigmaxi Thank you for sharing...  1369755736805416961   \n",
       "19  RT @TAMUGradSchool: Interested in a career in ...  1369733522815152129   \n",
       "\n",
       "    Is_retweet  Is_quote  Is_reply      Reply_of   Replying_to  Retweets  \\\n",
       "0         True     False     False           NaN           NaN         1   \n",
       "1        False      True     False           NaN           NaN         0   \n",
       "2        False     False      True  1.394291e+18  9.130586e+17         0   \n",
       "3        False      True     False           NaN           NaN         0   \n",
       "4        False     False      True  1.390296e+18  9.130586e+17         1   \n",
       "5         True     False     False           NaN           NaN         2   \n",
       "6        False     False     False           NaN           NaN         1   \n",
       "7        False     False     False           NaN           NaN         1   \n",
       "8         True     False     False           NaN           NaN         3   \n",
       "9        False     False     False           NaN           NaN         0   \n",
       "10        True     False     False           NaN           NaN         9   \n",
       "11       False     False     False           NaN           NaN         1   \n",
       "12       False     False     False           NaN           NaN         2   \n",
       "13       False     False     False           NaN           NaN         0   \n",
       "14       False     False     False           NaN           NaN         0   \n",
       "15       False     False     False           NaN           NaN         0   \n",
       "16       False     False      True  1.371852e+18  9.233622e+17         0   \n",
       "17       False     False     False           NaN           NaN         0   \n",
       "18       False     False      True  1.369669e+18  3.867330e+07         1   \n",
       "19        True     False     False           NaN           NaN         3   \n",
       "\n",
       "    Favorites             Created  \\\n",
       "0           0 2021-05-20 02:52:07   \n",
       "1           1 2021-05-17 14:42:41   \n",
       "2           1 2021-05-17 14:42:03   \n",
       "3           4 2021-05-07 00:26:58   \n",
       "4           6 2021-05-07 00:17:38   \n",
       "5           0 2021-04-30 11:34:51   \n",
       "6           9 2021-04-29 01:18:43   \n",
       "7           1 2021-04-22 15:54:57   \n",
       "8           0 2021-04-20 23:53:01   \n",
       "9           0 2021-04-11 20:16:11   \n",
       "10          0 2021-04-03 00:25:21   \n",
       "11          2 2021-04-01 02:08:33   \n",
       "12         11 2021-03-29 13:45:23   \n",
       "13          0 2021-03-25 16:27:46   \n",
       "14          4 2021-03-24 15:34:43   \n",
       "15          2 2021-03-18 20:09:19   \n",
       "16          1 2021-03-16 17:25:45   \n",
       "17          1 2021-03-15 16:10:47   \n",
       "18          0 2021-03-10 21:03:11   \n",
       "19          0 2021-03-10 19:34:54   \n",
       "\n",
       "                                              Cleaned  Time_since_last  \\\n",
       "0                      rt one week data scienc lectur  2 days 12:09:26   \n",
       "1                                     dream come true  0 days 00:00:38   \n",
       "2                                excel content screen 10 days 14:15:05   \n",
       "3   may data scienc boot camp full swing photo credit  0 days 00:09:20   \n",
       "4            retweet ever photo data scienc boot camp  6 days 12:42:47   \n",
       "5    rt osu math professor match ph privat sector job  1 days 10:16:08   \n",
       "6   may data scienc boot camp grad student postdoc...  6 days 09:23:46   \n",
       "7   invit industri continu tonight kenneth maynard...  1 days 16:01:56   \n",
       "8   rt hidden figur cours develop dr ranthoni edmo...  9 days 03:36:50   \n",
       "9   invit industri continu monday thoma sznigir st...  8 days 19:50:50   \n",
       "10  rt schr dinger chief biomed scientist karen ak...  1 days 22:16:48   \n",
       "11  invit industri continu thu senior ux research ...  2 days 12:23:10   \n",
       "12  join us invit industri tonight astronomi phd a...  3 days 21:17:37   \n",
       "13  invit industri continu tonight traymon beaver ...  1 days 00:53:03   \n",
       "14  may boot camp particip technic interview prep ...  5 days 19:25:24   \n",
       "15    join us even invit industri manag advanc analyt  2 days 02:43:34   \n",
       "16                                                     1 days 01:14:58   \n",
       "17  invit industri continu tonight march th ana mo...  4 days 19:07:36   \n",
       "18   thank share chang zoom link event help prevent u  0 days 01:28:17   \n",
       "19  rt interest career program develop mgmt amp ev...              NaT   \n",
       "\n",
       "    Streak of 1:00:00  Streak of 1 day, 0:00:00  Per 1:00:00  \\\n",
       "0                   1                         1            1   \n",
       "1                   2                         2            2   \n",
       "2                   2                         2            2   \n",
       "3                   2                         2            2   \n",
       "4                   2                         2            2   \n",
       "5                   1                         1            1   \n",
       "6                   1                         1            1   \n",
       "7                   1                         1            1   \n",
       "8                   1                         1            1   \n",
       "9                   1                         1            1   \n",
       "10                  1                         1            1   \n",
       "11                  1                         1            1   \n",
       "12                  1                         1            1   \n",
       "13                  1                         1            1   \n",
       "14                  1                         1            1   \n",
       "15                  1                         1            1   \n",
       "16                  1                         1            1   \n",
       "17                  1                         1            1   \n",
       "18                  1                         2            1   \n",
       "19                  1                         2            1   \n",
       "\n",
       "    Per 1 day, 0:00:00  \n",
       "0                    1  \n",
       "1                    2  \n",
       "2                    2  \n",
       "3                    2  \n",
       "4                    2  \n",
       "5                    1  \n",
       "6                    1  \n",
       "7                    1  \n",
       "8                    1  \n",
       "9                    1  \n",
       "10                   1  \n",
       "11                   1  \n",
       "12                   1  \n",
       "13                   1  \n",
       "14                   1  \n",
       "15                   1  \n",
       "16                   1  \n",
       "17                   1  \n",
       "18                   2  \n",
       "19                   2  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = get_activity('erdosinstitute')\n",
    "prep_activity(activity)\n",
    "activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "cf5f3993",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_activity(activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1c79bb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Id</th>\n",
       "      <th>Created</th>\n",
       "      <th>Is reply</th>\n",
       "      <th>Reply_of</th>\n",
       "      <th>Replying_to</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Is_retweet</th>\n",
       "      <th>Time_since_last</th>\n",
       "      <th>Streak of 1:00:00</th>\n",
       "      <th>Per 1 day, 0:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @AstronomerPat: @RacineSwick @WorkWithVari ...</td>\n",
       "      <td>1395210702869118982</td>\n",
       "      <td>2021-05-20 02:52:07</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2 days 12:09:26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dreams can come true @AstronomerPat https://t....</td>\n",
       "      <td>1394302356267880449</td>\n",
       "      <td>2021-05-17 14:42:41</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 00:00:38</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@AstronomerPat @WorkWithVari Same excellent co...</td>\n",
       "      <td>1394302197006053379</td>\n",
       "      <td>2021-05-17 14:42:03</td>\n",
       "      <td>True</td>\n",
       "      <td>1.394291e+18</td>\n",
       "      <td>9.130586e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>10 days 14:15:05</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Our May Data Science Boot Camp is in full swin...</td>\n",
       "      <td>1390463130627674113</td>\n",
       "      <td>2021-05-07 00:26:58</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 00:09:20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@AstronomerPat @MattOsborne71: This is the mos...</td>\n",
       "      <td>1390460782647906306</td>\n",
       "      <td>2021-05-07 00:17:38</td>\n",
       "      <td>True</td>\n",
       "      <td>1.390296e+18</td>\n",
       "      <td>9.130586e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>6 days 12:42:47</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @columbusbiz1st: How an OSU math professor ...</td>\n",
       "      <td>1388094491609997320</td>\n",
       "      <td>2021-04-30 11:34:51</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1 days 10:16:08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Our May Data Science Boot Camp with over 350 g...</td>\n",
       "      <td>1387577050735812608</td>\n",
       "      <td>2021-04-29 01:18:43</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>6 days 09:23:46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Invitations to Industry continues tonight with...</td>\n",
       "      <td>1385260846515773444</td>\n",
       "      <td>2021-04-22 15:54:57</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1 days 16:01:56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @OSUmath: The Hidden Figures course develop...</td>\n",
       "      <td>1384656382406840329</td>\n",
       "      <td>2021-04-20 23:53:01</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>9 days 03:36:50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Invitations to Industry continues Monday 04/12...</td>\n",
       "      <td>1381340320051384321</td>\n",
       "      <td>2021-04-11 20:16:11</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>8 days 19:50:50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @Schrodinger: Schrödinger’s Chief Biomedica...</td>\n",
       "      <td>1378141537788432384</td>\n",
       "      <td>2021-04-03 00:25:21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1 days 22:16:48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Invitations to Industry continues Thu 04/01 wi...</td>\n",
       "      <td>1377442729899212805</td>\n",
       "      <td>2021-04-01 02:08:33</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>2 days 12:23:10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Join us for Invitations to Industry tonight wi...</td>\n",
       "      <td>1376530932233076741</td>\n",
       "      <td>2021-03-29 13:45:23</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>3 days 21:17:37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Invitations to Industry continues tonight with...</td>\n",
       "      <td>1375122247334166529</td>\n",
       "      <td>2021-03-25 16:27:46</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1 days 00:53:03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>May 2021 Boot Camp Participants, Technical Int...</td>\n",
       "      <td>1374746507400859648</td>\n",
       "      <td>2021-03-24 15:34:43</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>5 days 19:25:24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Join us this evening for Invitations to Indust...</td>\n",
       "      <td>1372641283718664195</td>\n",
       "      <td>2021-03-18 20:09:19</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>2 days 02:43:34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@EmilyJoGriffith 🚀</td>\n",
       "      <td>1371875346715451401</td>\n",
       "      <td>2021-03-16 17:25:45</td>\n",
       "      <td>True</td>\n",
       "      <td>1.371852e+18</td>\n",
       "      <td>9.233622e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1 days 01:14:58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Invitations to Industry continues tonight Marc...</td>\n",
       "      <td>1371494092773994496</td>\n",
       "      <td>2021-03-15 16:10:47</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4 days 19:07:36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@TAMUGradSchool @sigmaxi Thank you for sharing...</td>\n",
       "      <td>1369755736805416961</td>\n",
       "      <td>2021-03-10 21:03:11</td>\n",
       "      <td>True</td>\n",
       "      <td>1.369669e+18</td>\n",
       "      <td>3.867330e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 01:28:17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RT @TAMUGradSchool: Interested in a career in ...</td>\n",
       "      <td>1369733522815152129</td>\n",
       "      <td>2021-03-10 19:34:54</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text                   Id  \\\n",
       "0   RT @AstronomerPat: @RacineSwick @WorkWithVari ...  1395210702869118982   \n",
       "1   Dreams can come true @AstronomerPat https://t....  1394302356267880449   \n",
       "2   @AstronomerPat @WorkWithVari Same excellent co...  1394302197006053379   \n",
       "3   Our May Data Science Boot Camp is in full swin...  1390463130627674113   \n",
       "4   @AstronomerPat @MattOsborne71: This is the mos...  1390460782647906306   \n",
       "5   RT @columbusbiz1st: How an OSU math professor ...  1388094491609997320   \n",
       "6   Our May Data Science Boot Camp with over 350 g...  1387577050735812608   \n",
       "7   Invitations to Industry continues tonight with...  1385260846515773444   \n",
       "8   RT @OSUmath: The Hidden Figures course develop...  1384656382406840329   \n",
       "9   Invitations to Industry continues Monday 04/12...  1381340320051384321   \n",
       "10  RT @Schrodinger: Schrödinger’s Chief Biomedica...  1378141537788432384   \n",
       "11  Invitations to Industry continues Thu 04/01 wi...  1377442729899212805   \n",
       "12  Join us for Invitations to Industry tonight wi...  1376530932233076741   \n",
       "13  Invitations to Industry continues tonight with...  1375122247334166529   \n",
       "14  May 2021 Boot Camp Participants, Technical Int...  1374746507400859648   \n",
       "15  Join us this evening for Invitations to Indust...  1372641283718664195   \n",
       "16                                 @EmilyJoGriffith 🚀  1371875346715451401   \n",
       "17  Invitations to Industry continues tonight Marc...  1371494092773994496   \n",
       "18  @TAMUGradSchool @sigmaxi Thank you for sharing...  1369755736805416961   \n",
       "19  RT @TAMUGradSchool: Interested in a career in ...  1369733522815152129   \n",
       "\n",
       "               Created  Is reply      Reply_of   Replying_to  Retweets  \\\n",
       "0  2021-05-20 02:52:07     False           NaN           NaN         1   \n",
       "1  2021-05-17 14:42:41     False           NaN           NaN         0   \n",
       "2  2021-05-17 14:42:03      True  1.394291e+18  9.130586e+17         0   \n",
       "3  2021-05-07 00:26:58     False           NaN           NaN         0   \n",
       "4  2021-05-07 00:17:38      True  1.390296e+18  9.130586e+17         1   \n",
       "5  2021-04-30 11:34:51     False           NaN           NaN         2   \n",
       "6  2021-04-29 01:18:43     False           NaN           NaN         1   \n",
       "7  2021-04-22 15:54:57     False           NaN           NaN         1   \n",
       "8  2021-04-20 23:53:01     False           NaN           NaN         3   \n",
       "9  2021-04-11 20:16:11     False           NaN           NaN         0   \n",
       "10 2021-04-03 00:25:21     False           NaN           NaN         9   \n",
       "11 2021-04-01 02:08:33     False           NaN           NaN         1   \n",
       "12 2021-03-29 13:45:23     False           NaN           NaN         2   \n",
       "13 2021-03-25 16:27:46     False           NaN           NaN         0   \n",
       "14 2021-03-24 15:34:43     False           NaN           NaN         0   \n",
       "15 2021-03-18 20:09:19     False           NaN           NaN         0   \n",
       "16 2021-03-16 17:25:45      True  1.371852e+18  9.233622e+17         0   \n",
       "17 2021-03-15 16:10:47     False           NaN           NaN         0   \n",
       "18 2021-03-10 21:03:11      True  1.369669e+18  3.867330e+07         1   \n",
       "19 2021-03-10 19:34:54     False           NaN           NaN         3   \n",
       "\n",
       "    Favorites  Is_retweet  Time_since_last  Streak of 1:00:00  \\\n",
       "0           0        True  2 days 12:09:26                  1   \n",
       "1           1       False  0 days 00:00:38                  2   \n",
       "2           1       False 10 days 14:15:05                  2   \n",
       "3           4       False  0 days 00:09:20                  2   \n",
       "4           6       False  6 days 12:42:47                  2   \n",
       "5           0        True  1 days 10:16:08                  1   \n",
       "6           9       False  6 days 09:23:46                  1   \n",
       "7           1       False  1 days 16:01:56                  1   \n",
       "8           0        True  9 days 03:36:50                  1   \n",
       "9           0       False  8 days 19:50:50                  1   \n",
       "10          0        True  1 days 22:16:48                  1   \n",
       "11          2       False  2 days 12:23:10                  1   \n",
       "12         11       False  3 days 21:17:37                  1   \n",
       "13          0       False  1 days 00:53:03                  1   \n",
       "14          4       False  5 days 19:25:24                  1   \n",
       "15          2       False  2 days 02:43:34                  1   \n",
       "16          1       False  1 days 01:14:58                  1   \n",
       "17          1       False  4 days 19:07:36                  1   \n",
       "18          0       False  0 days 01:28:17                  1   \n",
       "19          0        True              NaT                  1   \n",
       "\n",
       "    Per 1 day, 0:00:00  \n",
       "0                    1  \n",
       "1                    2  \n",
       "2                    2  \n",
       "3                    2  \n",
       "4                    2  \n",
       "5                    1  \n",
       "6                    1  \n",
       "7                    1  \n",
       "8                    1  \n",
       "9                    1  \n",
       "10                   1  \n",
       "11                   1  \n",
       "12                   1  \n",
       "13                   1  \n",
       "14                   1  \n",
       "15                   1  \n",
       "16                   1  \n",
       "17                   1  \n",
       "18                   2  \n",
       "19                   2  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da1732c",
   "metadata": {},
   "source": [
    "Building a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2993f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_core(user, breadth=10, depth=2, core=[], save=False):\n",
    "    #type user as a screen name so this works\n",
    "    howrite = 'a'\n",
    "    \n",
    "    # Make sure we're finding the right user\n",
    "    if type(user)==str:\n",
    "        user = API.get_user(screen_name=user).id\n",
    "        howrite = 'w'\n",
    "    elif type(user)!=int:\n",
    "        raise Exception(\"Bad user.\")\n",
    "    \n",
    "    #make sure we have good data\n",
    "    try:\n",
    "        friends = API.friends_ids(user_id=user)\n",
    "        friends[0]\n",
    "    except: \n",
    "        return False\n",
    "    \n",
    "    #one list for user's mutuals, one list for everyone\n",
    "    mutuals = []\n",
    "    core.append(user)\n",
    "    if save:\n",
    "        try:\n",
    "            with open(save, howrite) as save_file:\n",
    "                save_file.write(str(user)+'\\n')\n",
    "        except: \n",
    "            raise Exception('Bad save file')\n",
    "    \n",
    "    #we won't delve too deep or too greedily\n",
    "    if depth:\n",
    "        #find random friends of user who follow user back (mutuals)\n",
    "        for friend in np.random.permutation(friends):\n",
    "            friend = int(friend)\n",
    "            if friend not in core:\n",
    "                if API.show_friendship(source_id=friend, target_id=user)[0].following:\n",
    "                    #find their mutuals, but only add them to the list if it's good data\n",
    "                    if build_core(friend, breadth=breadth, depth=depth-1, core=core, save=save):\n",
    "                        #add them to the list\n",
    "                        mutuals.append(friend)\n",
    "                    #but only some of them\n",
    "                    if len(mutuals)==breadth:\n",
    "                        print(friend,'has mutuals',mutuals)\n",
    "                        break\n",
    "    \n",
    "    #and here's the list\n",
    "    return core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf9d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_crust(core, breadth=100, crust=[], save=False):\n",
    "    #initialize a list for the crust\n",
    "    crust = core.copy()\n",
    "    \n",
    "    #and a save file if neccessary\n",
    "    if save:\n",
    "        try:\n",
    "            with open(save, 'w') as save_file:\n",
    "                for core_member in core:\n",
    "                    save_file.write(str(core_member)+'\\n')\n",
    "        except: \n",
    "            raise Exception('Bad save file')\n",
    "        \n",
    "    #for each member of the core...\n",
    "    for core_member in core.copy():   \n",
    "        skip_number = 0\n",
    "        #add breadth number...\n",
    "        follow_number = 0\n",
    "        #of the core  member's...\n",
    "        followers = np.random.permutation(API.followers_ids(user_id=core_member))\n",
    "        \n",
    "        #followers to the crust...\n",
    "        for follower in followers:\n",
    "            follower = int(follower)\n",
    "            \n",
    "            #if they are accessible...\n",
    "            try:\n",
    "                getted = API.get_user(user_id=follower)\n",
    "                if getted.protected:\n",
    "                    raise Exception('Skip this one')\n",
    "            except:\n",
    "                skip_number += 1\n",
    "                continue\n",
    "                \n",
    "            #and aren't already in it\n",
    "            if follower not in crust:\n",
    "                crust.append(follower)\n",
    "                if save:\n",
    "                    with open(save, 'a') as save_file:\n",
    "                        save_file.write(str(follower)+'\\n')\n",
    "                follow_number += 1\n",
    "                if follow_number == breadth:\n",
    "                    break\n",
    "            else:\n",
    "                skip_number += 1\n",
    "        #keep tabs on how the script is going\n",
    "        print('got',follow_number,'followers of',core_member,'while skipping',skip_number)\n",
    "    \n",
    "    return crust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2190a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_data(core, crust, data=[], save=False, restart=0):\n",
    "    #we assign core members as features\n",
    "    columns = ['user']+['core_'+str(n) for n in range(len(core))]\n",
    "    if save and not restart: \n",
    "        with open(save, 'r') as save_file:\n",
    "            text = [''] + save_file.readlines()\n",
    "        for column in columns:\n",
    "            text[0] += ',' + str(column)\n",
    "        text[0] += '\\n'\n",
    "        with open(save, 'w+') as save_file:\n",
    "            save_file.writelines(text)\n",
    "        \n",
    "    #now we see which crust members are following which core members\n",
    "    for n, crust_member in [x for x in enumerate(crust) if x[0]>=restart]:\n",
    "        #this will hold what we find\n",
    "        next_line = [crust_member]\n",
    "        #look up who the crust member is following\n",
    "        following, pages = API.friends_ids(user_id=crust_member, cursor=-1)\n",
    "        \n",
    "        for core_member in core:\n",
    "            #page through if necessary\n",
    "            while pages[1] and (core_member not in following):\n",
    "                more_following, pages = API.friends_ids(user_id=crust_member, cursor=pages[1])\n",
    "                following += more_following\n",
    "            next_line.append(core_member in following)\n",
    "        \n",
    "        #We'll say people follow themselves\n",
    "        if n < len(core):\n",
    "            next_line[n]==True\n",
    "        \n",
    "        #now we store it\n",
    "        data.append(next_line)\n",
    "        if save: \n",
    "            with open(save, 'r') as save_file:\n",
    "                text = save_file.readlines()\n",
    "            text[n+1] = text[n+1][:-1]\n",
    "            for datum in next_line:\n",
    "                text[n+1] += ',' + str(datum)\n",
    "            text[n+1] += '\\n'\n",
    "            with open(save, 'w') as save_file:\n",
    "                save_file.writelines(text)\n",
    "        print('Stored data for member', n+1, 'of', len(crust))\n",
    "    \n",
    "    #and finally put it all together\n",
    "    return pd.DataFrame(data, index=crust, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b0de0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052051030 has mutuals [599767159, 1003398199, 707246777515245572, 277158689, 27104113, 18699142, 1631671458, 44691739, 4235197337, 1052051030]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716326749823438848 has mutuals [180705418, 1066585043626311680, 3354214695, 1099695707341180928, 1161814802, 96698038, 762470063261704192, 419084104, 1269613348003471360, 716326749823438848]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1470633924 has mutuals [262834701, 236287355, 36837114, 462494796, 48761924, 367479753, 395620849, 2740563252, 32691725, 1470633924]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104503831 has mutuals [18266688, 20792657, 110445334, 19115457, 232901331, 18247062, 147725246, 474232856, 825608011, 104503831]\n",
      "1165002047369826304 has mutuals [52050545, 1675743247, 999632589286670336, 1390840993, 4892988929, 2990685034, 547690781, 1546382263, 28650342, 1165002047369826304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34667097 has mutuals [22635112, 37040011, 25606255, 55456966, 45014496, 878247600096509952, 63769373, 25457754, 91508945, 34667097]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16175706 has mutuals [2483104627, 58807922, 842327754301423616, 2436338828, 465092949, 4802754257, 856877583803265025, 762789921933307904, 618356934, 16175706]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2665748041 has mutuals [821557387, 19613907, 756198843042193408, 18774951, 267944170, 3310505366, 37718165, 499771067, 45660732, 2665748041]\n",
      "111660650 has mutuals [2149677560, 2730264319, 902200087, 217634501, 3165740402, 18410315, 449850814, 434458299, 3407890707, 111660650]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30721022 has mutuals [1584092041, 142297864, 72002979, 540240770, 34951162, 280339608, 2272305950, 2268158728, 24880132, 30721022]\n",
      "39797085 has mutuals [36432879, 18080108, 56319954, 107125748, 98240178, 16869718, 71675903, 25443684, 4532518512, 39797085]\n"
     ]
    }
   ],
   "source": [
    "tomi_core = build_core('TomiLahren', save='Tomi_core.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2192aef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 from number 0\n",
      "Found 100 from number 1\n",
      "Found 99 from number 2\n",
      "Found 61 from number 3\n",
      "Found 64 from number 4\n",
      "Found 100 from number 5\n",
      "Found 6 from number 6\n",
      "Found 100 from number 7\n",
      "Found 8 from number 8\n",
      "Found 100 from number 9\n",
      "Found 3 from number 10\n",
      "Found 0 from number 11\n",
      "Found 99 from number 12\n",
      "Found 100 from number 13\n",
      "Found 100 from number 14\n",
      "Found 100 from number 15\n",
      "Found 100 from number 16\n",
      "Found 99 from number 17\n",
      "Found 100 from number 18\n",
      "Found 42 from number 19\n",
      "Found 100 from number 20\n",
      "Found 100 from number 21\n",
      "Found 100 from number 22\n",
      "Found 36 from number 23\n",
      "Found 100 from number 24\n",
      "Found 100 from number 25\n",
      "Found 100 from number 26\n",
      "Found 63 from number 27\n",
      "Found 100 from number 28\n",
      "Found 100 from number 29\n",
      "Found 0 from number 30\n",
      "Found 99 from number 31\n",
      "Found 99 from number 32\n",
      "Found 98 from number 33\n",
      "Found 100 from number 34\n",
      "Found 100 from number 35\n",
      "Found 16 from number 36\n",
      "Found 2 from number 37\n",
      "Found 68 from number 38\n",
      "Found 99 from number 39\n",
      "Found 100 from number 40\n",
      "Found 100 from number 41\n",
      "Found 9 from number 42\n",
      "Found 60 from number 43\n",
      "Found 100 from number 44\n",
      "Found 100 from number 45\n",
      "Found 100 from number 46\n",
      "Found 92 from number 47\n",
      "Found 100 from number 48\n",
      "Found 35 from number 49\n",
      "Found 99 from number 50\n",
      "Found 100 from number 51\n",
      "Found 100 from number 52\n",
      "Found 99 from number 53\n",
      "Found 100 from number 54\n",
      "Found 100 from number 55\n",
      "Found 100 from number 56\n",
      "Found 100 from number 57\n",
      "Found 100 from number 58\n",
      "Found 35 from number 59\n",
      "Found 1 from number 60\n",
      "Found 100 from number 61\n",
      "Found 100 from number 62\n",
      "Found 100 from number 63\n",
      "Found 98 from number 64\n",
      "Found 98 from number 65\n",
      "Found 26 from number 66\n",
      "Found 100 from number 67\n",
      "Found 100 from number 68\n",
      "Found 3 from number 69\n",
      "Found 7 from number 70\n",
      "Found 3 from number 71\n",
      "Found 69 from number 72\n",
      "Found 88 from number 73\n",
      "Found 100 from number 74\n",
      "Found 99 from number 75\n",
      "Found 11 from number 76\n",
      "Found 100 from number 77\n",
      "Found 100 from number 78\n",
      "Found 100 from number 79\n",
      "Found 100 from number 80\n",
      "Found 100 from number 81\n",
      "Found 100 from number 82\n",
      "Found 1 from number 83\n",
      "Found 99 from number 84\n",
      "Found 30 from number 85\n",
      "Found 100 from number 86\n",
      "Found 100 from number 87\n",
      "Found 65 from number 88\n",
      "Found 100 from number 89\n",
      "Found 97 from number 90\n",
      "Found 100 from number 91\n",
      "Found 99 from number 92\n",
      "Found 99 from number 93\n",
      "Found 100 from number 94\n",
      "Found 100 from number 95\n",
      "Found 99 from number 96\n",
      "Found 15 from number 97\n",
      "Found 44 from number 98\n",
      "Found 25 from number 99\n",
      "Found 100 from number 100\n",
      "Found 100 from number 101\n",
      "Found 100 from number 102\n",
      "Found 3 from number 103\n",
      "Found 100 from number 104\n",
      "Found 98 from number 105\n",
      "Found 94 from number 106\n",
      "Found 0 from number 107\n",
      "Found 100 from number 108\n",
      "Found 100 from number 109\n",
      "Found 100 from number 110\n",
      "Found 0 from number 111\n",
      "Found 43 from number 112\n",
      "Found 99 from number 113\n",
      "Found 100 from number 114\n",
      "Found 100 from number 115\n",
      "Found 96 from number 116\n",
      "Found 100 from number 117\n",
      "Found 100 from number 118\n",
      "Found 99 from number 119\n",
      "Found 99 from number 120\n",
      "Found 100 from number 121\n",
      "Found 100 from number 122\n",
      "Found 77 from number 123\n",
      "Found 100 from number 124\n",
      "Found 100 from number 125\n",
      "Found 45 from number 126\n",
      "Found 27 from number 127\n",
      "Found 55 from number 128\n",
      "Found 15 from number 129\n",
      "Found 99 from number 130\n",
      "Found 100 from number 131\n",
      "Found 100 from number 132\n",
      "Found 100 from number 133\n",
      "Found 100 from number 134\n",
      "Found 100 from number 135\n",
      "Found 100 from number 136\n",
      "Found 99 from number 137\n",
      "Found 100 from number 138\n",
      "Found 100 from number 139\n",
      "Found 100 from number 140\n",
      "Found 63 from number 141\n",
      "Found 34 from number 142\n",
      "Found 100 from number 143\n",
      "Found 25 from number 144\n",
      "Found 100 from number 145\n",
      "Found 100 from number 146\n",
      "Found 98 from number 147\n",
      "Found 97 from number 148\n",
      "Found 100 from number 149\n",
      "Found 100 from number 150\n",
      "Found 100 from number 151\n",
      "Found 100 from number 152\n",
      "Found 99 from number 153\n",
      "Found 99 from number 154\n",
      "Found 100 from number 155\n",
      "Found 100 from number 156\n",
      "Found 100 from number 157\n",
      "Found 98 from number 158\n",
      "Found 99 from number 159\n",
      "Found 100 from number 160\n",
      "Found 93 from number 161\n",
      "Found 100 from number 162\n",
      "Found 100 from number 163\n",
      "Found 55 from number 164\n",
      "Found 93 from number 165\n",
      "Found 100 from number 166\n",
      "Found 100 from number 167\n",
      "Found 4 from number 168\n",
      "Found 100 from number 169\n",
      "Found 88 from number 170\n",
      "Found 100 from number 171\n",
      "Found 100 from number 172\n",
      "Found 99 from number 173\n",
      "Found 98 from number 174\n",
      "Found 41 from number 175\n",
      "Found 100 from number 176\n",
      "Found 100 from number 177\n",
      "Found 100 from number 178\n",
      "Found 100 from number 179\n",
      "Found 100 from number 180\n",
      "Found 32 from number 181\n",
      "Found 100 from number 182\n",
      "Found 100 from number 183\n",
      "Found 93 from number 184\n",
      "Found 100 from number 185\n",
      "Found 100 from number 186\n",
      "Found 4 from number 187\n",
      "Found 100 from number 188\n",
      "Found 100 from number 189\n",
      "Found 99 from number 190\n",
      "Found 100 from number 191\n",
      "Found 100 from number 192\n",
      "Found 100 from number 193\n",
      "Found 100 from number 194\n",
      "Found 100 from number 195\n",
      "Found 13 from number 196\n",
      "Found 34 from number 197\n",
      "Found 100 from number 198\n",
      "Found 100 from number 199\n",
      "Found 27 from number 200\n",
      "Found 100 from number 201\n",
      "Found 100 from number 202\n",
      "Found 100 from number 203\n",
      "Found 100 from number 204\n",
      "Found 97 from number 205\n",
      "Found 63 from number 206\n",
      "Found 100 from number 207\n",
      "Found 100 from number 208\n",
      "Found 100 from number 209\n",
      "Found 45 from number 210\n",
      "Found 19 from number 211\n",
      "Found 100 from number 212\n",
      "Found 37 from number 213\n",
      "Found 65 from number 214\n",
      "Found 97 from number 215\n",
      "Found 100 from number 216\n",
      "Found 100 from number 217\n",
      "Found 94 from number 218\n",
      "Found 58 from number 219\n",
      "Found 100 from number 220\n",
      "Found 100 from number 221\n",
      "Found 100 from number 222\n",
      "Found 18 from number 223\n",
      "Found 100 from number 224\n",
      "Found 100 from number 225\n",
      "Found 100 from number 226\n",
      "Found 100 from number 227\n",
      "Found 97 from number 228\n",
      "Found 100 from number 229\n",
      "Found 6 from number 230\n",
      "Found 99 from number 231\n",
      "Found 100 from number 232\n",
      "Found 50 from number 233\n",
      "Found 100 from number 234\n",
      "Found 100 from number 235\n",
      "Found 100 from number 236\n",
      "Found 97 from number 237\n",
      "Found 100 from number 238\n",
      "Found 52 from number 239\n",
      "Found 10 from number 240\n",
      "Found 100 from number 241\n",
      "Found 100 from number 242\n",
      "Found 100 from number 243\n",
      "Found 100 from number 244\n",
      "Found 23 from number 245\n",
      "Found 100 from number 246\n",
      "Found 100 from number 247\n",
      "Found 19 from number 248\n",
      "Found 99 from number 249\n",
      "Found 74 from number 250\n",
      "Found 99 from number 251\n",
      "Found 100 from number 252\n",
      "Found 99 from number 253\n",
      "Found 58 from number 254\n",
      "Found 82 from number 255\n",
      "Found 4 from number 256\n",
      "Found 100 from number 257\n",
      "Found 14 from number 258\n",
      "Found 100 from number 259\n",
      "Found 1 from number 260\n",
      "Found 100 from number 261\n",
      "Found 28 from number 262\n",
      "Found 100 from number 263\n",
      "Found 0 from number 264\n",
      "Found 100 from number 265\n",
      "Found 99 from number 266\n",
      "Found 4 from number 267\n",
      "Found 100 from number 268\n",
      "Found 100 from number 269\n",
      "Found 70 from number 270\n",
      "Found 100 from number 271\n",
      "Found 100 from number 272\n",
      "Found 2 from number 273\n",
      "Found 100 from number 274\n",
      "Found 19 from number 275\n",
      "Found 100 from number 276\n",
      "Found 14 from number 277\n",
      "Found 93 from number 278\n",
      "Found 97 from number 279\n",
      "Found 100 from number 280\n",
      "Found 100 from number 281\n",
      "Found 100 from number 282\n",
      "Found 100 from number 283\n",
      "Found 100 from number 284\n",
      "Found 11 from number 285\n",
      "Found 42 from number 286\n",
      "Found 0 from number 287\n",
      "Found 1 from number 288\n",
      "Found 99 from number 289\n",
      "Found 0 from number 290\n",
      "Found 98 from number 291\n",
      "Found 69 from number 292\n",
      "Found 100 from number 293\n",
      "Found 99 from number 294\n",
      "Found 77 from number 295\n",
      "Found 89 from number 296\n",
      "Found 0 from number 297\n",
      "Found 1 from number 298\n",
      "Found 100 from number 299\n",
      "Found 99 from number 300\n",
      "Found 4 from number 301\n",
      "Found 100 from number 302\n",
      "Found 1 from number 303\n",
      "Found 100 from number 304\n",
      "Found 100 from number 305\n",
      "Found 98 from number 306\n",
      "Found 100 from number 307\n",
      "Found 100 from number 308\n",
      "Found 100 from number 309\n",
      "Found 100 from number 310\n",
      "Found 100 from number 311\n",
      "Found 100 from number 312\n",
      "Found 99 from number 313\n",
      "Found 86 from number 314\n",
      "Found 2 from number 315\n",
      "Found 98 from number 316\n",
      "Found 66 from number 317\n",
      "Found 100 from number 318\n",
      "Found 100 from number 319\n",
      "Found 100 from number 320\n",
      "Found 100 from number 321\n",
      "Found 100 from number 322\n",
      "Found 93 from number 323\n",
      "Found 28 from number 324\n",
      "Found 34 from number 325\n",
      "Found 100 from number 326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 from number 327\n",
      "Found 2 from number 328\n",
      "Found 100 from number 329\n",
      "Found 54 from number 330\n",
      "Found 100 from number 331\n",
      "Found 100 from number 332\n",
      "Found 100 from number 333\n",
      "Found 100 from number 334\n",
      "Found 16 from number 335\n",
      "Found 100 from number 336\n",
      "Found 8 from number 337\n",
      "Found 97 from number 338\n",
      "Found 7 from number 339\n",
      "Found 100 from number 340\n",
      "Found 100 from number 341\n",
      "Found 99 from number 342\n",
      "Found 100 from number 343\n",
      "Found 97 from number 344\n",
      "Found 100 from number 345\n",
      "Found 100 from number 346\n",
      "Found 100 from number 347\n",
      "Found 100 from number 348\n",
      "Found 100 from number 349\n",
      "Found 100 from number 350\n",
      "Found 100 from number 351\n",
      "Found 100 from number 352\n",
      "Found 1 from number 353\n",
      "Found 100 from number 354\n",
      "Found 100 from number 355\n",
      "Found 100 from number 356\n",
      "Found 36 from number 357\n",
      "Found 100 from number 358\n",
      "Found 100 from number 359\n",
      "Found 100 from number 360\n",
      "Found 1 from number 361\n",
      "Found 100 from number 362\n",
      "Found 100 from number 363\n",
      "Found 100 from number 364\n",
      "Found 100 from number 365\n",
      "Found 99 from number 366\n",
      "Found 17 from number 367\n",
      "Found 100 from number 368\n",
      "Found 99 from number 369\n",
      "Found 100 from number 370\n",
      "Found 100 from number 371\n",
      "Found 100 from number 372\n",
      "Found 82 from number 373\n",
      "Found 100 from number 374\n",
      "Found 6 from number 375\n",
      "Found 95 from number 376\n",
      "Found 100 from number 377\n",
      "Found 100 from number 378\n",
      "Found 100 from number 379\n",
      "Found 77 from number 380\n",
      "Found 100 from number 381\n",
      "Found 100 from number 382\n",
      "Found 47 from number 383\n",
      "Found 100 from number 384\n",
      "Found 52 from number 385\n",
      "Found 100 from number 386\n",
      "Found 100 from number 387\n",
      "Found 83 from number 388\n",
      "Found 89 from number 389\n",
      "Found 100 from number 390\n",
      "Found 9 from number 391\n",
      "Found 100 from number 392\n",
      "Found 99 from number 393\n",
      "Found 100 from number 394\n",
      "Found 63 from number 395\n",
      "Found 0 from number 396\n",
      "Found 59 from number 397\n",
      "Found 100 from number 398\n",
      "Found 100 from number 399\n",
      "Found 100 from number 400\n",
      "Found 77 from number 401\n",
      "Found 100 from number 402\n",
      "Found 100 from number 403\n",
      "Found 100 from number 404\n",
      "Found 100 from number 405\n",
      "Found 100 from number 406\n",
      "Found 100 from number 407\n",
      "Found 19 from number 408\n",
      "Found 100 from number 409\n",
      "Found 100 from number 410\n",
      "Found 100 from number 411\n",
      "Found 100 from number 412\n",
      "Found 100 from number 413\n",
      "Found 100 from number 414\n",
      "Found 21 from number 415\n",
      "Found 98 from number 416\n",
      "Found 100 from number 417\n",
      "Found 100 from number 418\n",
      "Found 100 from number 419\n",
      "Found 100 from number 420\n",
      "Found 100 from number 421\n",
      "Found 100 from number 422\n",
      "Found 100 from number 423\n",
      "Found 86 from number 424\n",
      "Found 98 from number 425\n",
      "Found 45 from number 426\n",
      "Found 100 from number 427\n",
      "Found 14 from number 428\n",
      "Found 6 from number 429\n",
      "Found 100 from number 430\n",
      "Found 99 from number 431\n",
      "Found 100 from number 432\n",
      "Found 100 from number 433\n",
      "Found 0 from number 434\n",
      "Found 11 from number 435\n",
      "Found 58 from number 436\n",
      "Found 100 from number 437\n",
      "Found 100 from number 438\n",
      "Found 95 from number 439\n",
      "Found 99 from number 440\n",
      "Found 99 from number 441\n",
      "Found 100 from number 442\n",
      "Found 100 from number 443\n",
      "Found 100 from number 444\n",
      "Found 32 from number 445\n",
      "Found 1 from number 446\n",
      "Found 100 from number 447\n",
      "Found 100 from number 448\n",
      "Found 100 from number 449\n",
      "Found 92 from number 450\n",
      "Found 99 from number 451\n",
      "Found 100 from number 452\n",
      "Found 100 from number 453\n",
      "Found 100 from number 454\n",
      "Found 100 from number 455\n",
      "Found 0 from number 456\n",
      "Found 100 from number 457\n",
      "Found 4 from number 458\n",
      "Found 100 from number 459\n",
      "Found 100 from number 460\n",
      "Found 100 from number 461\n",
      "Found 49 from number 462\n",
      "Found 100 from number 463\n",
      "Found 100 from number 464\n",
      "Found 100 from number 465\n",
      "Found 30 from number 466\n",
      "Found 1 from number 467\n",
      "Found 100 from number 468\n",
      "Found 99 from number 469\n",
      "Found 99 from number 470\n",
      "Found 100 from number 471\n",
      "Found 91 from number 472\n",
      "Found 100 from number 473\n",
      "Found 69 from number 474\n",
      "Found 45 from number 475\n",
      "Found 100 from number 476\n",
      "Found 100 from number 477\n",
      "Found 20 from number 478\n",
      "Found 67 from number 479\n",
      "Found 100 from number 480\n",
      "Found 100 from number 481\n",
      "Found 100 from number 482\n",
      "Found 0 from number 483\n",
      "Found 5 from number 484\n",
      "Found 100 from number 485\n",
      "Found 100 from number 486\n",
      "Found 100 from number 487\n",
      "Found 100 from number 488\n",
      "Found 100 from number 489\n",
      "Found 100 from number 490\n",
      "Found 100 from number 491\n",
      "Found 99 from number 492\n",
      "Found 83 from number 493\n",
      "Found 99 from number 494\n",
      "Found 100 from number 495\n",
      "Found 99 from number 496\n",
      "Found 100 from number 497\n",
      "Found 2 from number 498\n",
      "Found 100 from number 499\n",
      "Found 100 from number 500\n",
      "Found 99 from number 501\n",
      "Found 100 from number 502\n",
      "Found 15 from number 503\n",
      "Found 42 from number 504\n",
      "Found 100 from number 505\n",
      "Found 0 from number 506\n",
      "Found 99 from number 507\n",
      "Found 42 from number 508\n",
      "Found 100 from number 509\n",
      "Found 100 from number 510\n",
      "Found 100 from number 511\n",
      "Found 100 from number 512\n",
      "Found 100 from number 513\n",
      "Found 99 from number 514\n",
      "Found 100 from number 515\n",
      "Found 100 from number 516\n",
      "Found 98 from number 517\n",
      "Found 100 from number 518\n",
      "Found 100 from number 519\n",
      "Found 0 from number 520\n",
      "Found 100 from number 521\n",
      "Found 100 from number 522\n",
      "Found 17 from number 523\n",
      "Found 99 from number 524\n",
      "Found 100 from number 525\n",
      "Found 100 from number 526\n",
      "Found 100 from number 527\n",
      "Found 100 from number 528\n",
      "Found 99 from number 529\n",
      "Found 100 from number 530\n",
      "Found 100 from number 531\n",
      "Found 100 from number 532\n",
      "Found 100 from number 533\n",
      "Found 98 from number 534\n",
      "Found 100 from number 535\n",
      "Found 0 from number 536\n",
      "Found 100 from number 537\n",
      "Found 100 from number 538\n",
      "Found 40 from number 539\n",
      "Found 100 from number 540\n",
      "Found 22 from number 541\n",
      "Found 100 from number 542\n",
      "Found 85 from number 543\n",
      "Found 97 from number 544\n",
      "Found 6 from number 545\n",
      "Found 0 from number 546\n",
      "Found 10 from number 547\n",
      "Found 100 from number 548\n",
      "Found 4 from number 549\n",
      "Found 100 from number 550\n",
      "Found 23 from number 551\n",
      "Found 16 from number 552\n",
      "Found 86 from number 553\n",
      "Found 1 from number 554\n",
      "Found 80 from number 555\n",
      "Found 99 from number 556\n",
      "Found 100 from number 557\n",
      "Found 15 from number 558\n",
      "Found 100 from number 559\n",
      "Found 8 from number 560\n",
      "Found 38 from number 561\n",
      "Found 0 from number 562\n",
      "Found 82 from number 563\n",
      "Found 100 from number 564\n",
      "Found 100 from number 565\n",
      "Found 27 from number 566\n",
      "Found 95 from number 567\n",
      "Found 26 from number 568\n",
      "Found 0 from number 569\n",
      "Found 100 from number 570\n",
      "Found 100 from number 571\n",
      "Found 19 from number 572\n",
      "Found 6 from number 573\n",
      "Found 1 from number 574\n",
      "Found 99 from number 575\n",
      "Found 10 from number 576\n",
      "Found 100 from number 577\n",
      "Found 42 from number 578\n",
      "Found 72 from number 579\n",
      "Found 19 from number 580\n",
      "Found 99 from number 581\n",
      "Found 0 from number 582\n",
      "Found 99 from number 583\n",
      "Found 100 from number 584\n",
      "Found 100 from number 585\n",
      "Found 99 from number 586\n",
      "Found 99 from number 587\n",
      "Found 83 from number 588\n",
      "Found 51 from number 589\n",
      "Found 100 from number 590\n",
      "Found 100 from number 591\n",
      "Found 100 from number 592\n",
      "Found 0 from number 593\n",
      "Found 100 from number 594\n",
      "Found 100 from number 595\n",
      "Found 24 from number 596\n",
      "Found 100 from number 597\n",
      "Found 100 from number 598\n",
      "Found 98 from number 599\n",
      "Found 100 from number 600\n",
      "Found 75 from number 601\n",
      "Found 0 from number 602\n",
      "Found 13 from number 603\n",
      "Found 62 from number 604\n",
      "Found 1 from number 605\n",
      "Found 0 from number 606\n",
      "Found 3 from number 607\n",
      "Found 100 from number 608\n",
      "Found 97 from number 609\n",
      "Found 6 from number 610\n",
      "Found 2 from number 611\n",
      "Found 1 from number 612\n",
      "Found 100 from number 613\n",
      "Found 0 from number 614\n",
      "Found 100 from number 615\n",
      "Found 4 from number 616\n",
      "Found 100 from number 617\n",
      "Found 10 from number 618\n",
      "Found 100 from number 619\n",
      "Found 22 from number 620\n",
      "Found 0 from number 621\n",
      "Found 0 from number 622\n",
      "Found 3 from number 623\n",
      "Found 3 from number 624\n",
      "Found 100 from number 625\n",
      "Found 100 from number 626\n",
      "Found 100 from number 627\n",
      "Found 100 from number 628\n",
      "Found 45 from number 629\n",
      "Found 100 from number 630\n",
      "Found 4 from number 631\n",
      "Found 100 from number 632\n",
      "Found 94 from number 633\n",
      "Found 100 from number 634\n",
      "Found 20 from number 635\n",
      "Found 0 from number 636\n",
      "Found 3 from number 637\n",
      "Found 0 from number 638\n",
      "Found 37 from number 639\n",
      "Found 100 from number 640\n",
      "Found 100 from number 641\n",
      "Found 100 from number 642\n",
      "Found 96 from number 643\n",
      "Found 45 from number 644\n",
      "Found 100 from number 645\n",
      "Found 100 from number 646\n",
      "Found 100 from number 647\n",
      "Found 97 from number 648\n",
      "Found 100 from number 649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 from number 650\n",
      "Found 100 from number 651\n",
      "Found 100 from number 652\n",
      "Found 99 from number 653\n",
      "Found 100 from number 654\n",
      "Found 99 from number 655\n",
      "Found 100 from number 656\n",
      "Found 100 from number 657\n",
      "Found 100 from number 658\n",
      "Found 100 from number 659\n",
      "Found 100 from number 660\n",
      "Found 100 from number 661\n",
      "Found 100 from number 662\n",
      "Found 100 from number 663\n",
      "Found 100 from number 664\n",
      "Found 81 from number 665\n",
      "Found 99 from number 666\n",
      "Found 100 from number 667\n",
      "Found 100 from number 668\n",
      "Found 100 from number 669\n",
      "Found 100 from number 670\n",
      "Found 100 from number 671\n",
      "Found 7 from number 672\n",
      "Found 100 from number 673\n",
      "Found 20 from number 674\n",
      "Found 100 from number 675\n",
      "Found 0 from number 676\n",
      "Found 100 from number 677\n",
      "Found 100 from number 678\n",
      "Found 100 from number 679\n",
      "Found 97 from number 680\n",
      "Found 100 from number 681\n",
      "Found 100 from number 682\n",
      "Found 100 from number 683\n",
      "Found 100 from number 684\n",
      "Found 100 from number 685\n",
      "Found 100 from number 686\n",
      "Found 100 from number 687\n",
      "Found 100 from number 688\n",
      "Found 100 from number 689\n",
      "Found 100 from number 690\n",
      "Found 100 from number 691\n",
      "Found 100 from number 692\n",
      "Found 0 from number 693\n",
      "Found 100 from number 694\n",
      "Found 100 from number 695\n",
      "Found 13 from number 696\n",
      "Found 67 from number 697\n",
      "Found 100 from number 698\n",
      "Found 99 from number 699\n",
      "Found 100 from number 700\n",
      "Found 100 from number 701\n",
      "Found 100 from number 702\n",
      "Found 100 from number 703\n",
      "Found 99 from number 704\n",
      "Found 100 from number 705\n",
      "Found 98 from number 706\n",
      "Found 99 from number 707\n",
      "Found 100 from number 708\n",
      "Found 100 from number 709\n",
      "Found 99 from number 710\n",
      "Found 100 from number 711\n",
      "Found 100 from number 712\n",
      "Found 78 from number 713\n",
      "Found 100 from number 714\n",
      "Found 100 from number 715\n",
      "Found 13 from number 716\n",
      "Found 100 from number 717\n",
      "Found 100 from number 718\n",
      "Found 88 from number 719\n",
      "Found 0 from number 720\n",
      "Found 100 from number 721\n",
      "Found 100 from number 722\n",
      "Found 1 from number 723\n",
      "Found 50 from number 724\n",
      "Found 100 from number 725\n",
      "Found 55 from number 726\n",
      "Found 100 from number 727\n",
      "Found 100 from number 728\n",
      "Found 5 from number 729\n",
      "Found 100 from number 730\n",
      "Found 99 from number 731\n",
      "Found 100 from number 732\n",
      "Found 100 from number 733\n",
      "Found 0 from number 734\n",
      "Found 100 from number 735\n",
      "Found 100 from number 736\n",
      "Found 100 from number 737\n",
      "Found 12 from number 738\n",
      "Found 100 from number 739\n",
      "Found 98 from number 740\n",
      "Found 41 from number 741\n",
      "Found 100 from number 742\n",
      "Found 4 from number 743\n",
      "Found 99 from number 744\n",
      "Found 15 from number 745\n",
      "Found 100 from number 746\n",
      "Found 100 from number 747\n",
      "Found 96 from number 748\n",
      "Found 100 from number 749\n",
      "Found 100 from number 750\n",
      "Found 100 from number 751\n",
      "Found 0 from number 752\n",
      "Found 38 from number 753\n",
      "Found 100 from number 754\n",
      "Found 99 from number 755\n",
      "Found 47 from number 756\n",
      "Found 100 from number 757\n",
      "Found 85 from number 758\n",
      "Found 38 from number 759\n",
      "Found 17 from number 760\n",
      "Found 4 from number 761\n",
      "Found 100 from number 762\n",
      "Found 0 from number 763\n",
      "Found 100 from number 764\n",
      "Found 100 from number 765\n",
      "Found 100 from number 766\n",
      "Found 100 from number 767\n",
      "Found 100 from number 768\n",
      "Found 100 from number 769\n",
      "Found 100 from number 770\n",
      "Found 100 from number 771\n",
      "Found 100 from number 772\n",
      "Found 100 from number 773\n",
      "Found 5 from number 774\n",
      "Found 82 from number 775\n",
      "Found 36 from number 776\n",
      "Found 95 from number 777\n",
      "Found 54 from number 778\n",
      "Found 100 from number 779\n",
      "Found 100 from number 780\n",
      "Found 100 from number 781\n",
      "Found 100 from number 782\n",
      "Found 100 from number 783\n",
      "Found 55 from number 784\n",
      "Found 100 from number 785\n",
      "Found 100 from number 786\n",
      "Found 10 from number 787\n",
      "Found 100 from number 788\n",
      "Found 100 from number 789\n",
      "Found 0 from number 790\n",
      "Found 99 from number 791\n",
      "Found 100 from number 792\n",
      "Found 100 from number 793\n",
      "Found 100 from number 794\n",
      "Found 100 from number 795\n",
      "Found 100 from number 796\n",
      "Found 100 from number 797\n",
      "Found 100 from number 798\n",
      "Found 100 from number 799\n",
      "Found 16 from number 800\n",
      "Found 100 from number 801\n",
      "Found 99 from number 802\n",
      "Found 100 from number 803\n",
      "Found 100 from number 804\n",
      "Found 88 from number 805\n",
      "Found 69 from number 806\n",
      "Found 0 from number 807\n",
      "Found 100 from number 808\n",
      "Found 85 from number 809\n",
      "Found 100 from number 810\n",
      "Found 92 from number 811\n",
      "Found 100 from number 812\n",
      "Found 100 from number 813\n",
      "Found 100 from number 814\n",
      "Found 100 from number 815\n",
      "Found 100 from number 816\n",
      "Found 100 from number 817\n",
      "Found 97 from number 818\n",
      "Found 100 from number 819\n",
      "Found 100 from number 820\n",
      "Found 100 from number 821\n",
      "Found 100 from number 822\n",
      "Found 7 from number 823\n",
      "Found 93 from number 824\n",
      "Found 100 from number 825\n",
      "Found 100 from number 826\n",
      "Found 99 from number 827\n",
      "Found 100 from number 828\n",
      "Found 100 from number 829\n",
      "Found 94 from number 830\n",
      "Found 99 from number 831\n",
      "Found 100 from number 832\n",
      "Found 100 from number 833\n",
      "Found 100 from number 834\n",
      "Found 0 from number 835\n",
      "Found 97 from number 836\n",
      "Found 100 from number 837\n",
      "Found 15 from number 838\n",
      "Found 100 from number 839\n",
      "Found 100 from number 840\n",
      "Found 100 from number 841\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, crusty in enumerate(crust):\n",
    "    tweets = API.user_timeline(user_id=crusty, count=100)\n",
    "    tweets_array.append(tweets)\n",
    "    tweet_saver(tweets, '../Messing around/erdos_crust/'+str(i)+'.txt')\n",
    "    print('Found',len(tweets),'from number', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d2b2e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32f56eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('erdos_full_sample.csv', 'r') as reader:\n",
    "    lines = reader.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c584de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crust += [int(line) for line in lines[154:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "24760735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User(_api=<tweepy.api.API object at 0x000002327876BF48>, _json={'id': 80076948, 'id_str': '80076948', 'name': 'khadija', 'screen_name': 'unprotectedme', 'location': '', 'profile_location': None, 'description': '', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': True, 'followers_count': 2, 'friends_count': 63, 'listed_count': 0, 'created_at': 'Mon Oct 05 17:24:55 +0000 2009', 'favourites_count': 0, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 5, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '1A1B1F', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_tile': False, 'profile_image_url': 'http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'profile_image_url_https': 'https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'profile_link_color': '2FC2EF', 'profile_sidebar_border_color': '181A1E', 'profile_sidebar_fill_color': '252429', 'profile_text_color': '666666', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': True, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, id=80076948, id_str='80076948', name='khadija', screen_name='unprotectedme', location='', profile_location=None, description='', url=None, entities={'description': {'urls': []}}, protected=True, followers_count=2, friends_count=63, listed_count=0, created_at=datetime.datetime(2009, 10, 5, 17, 24, 55), favourites_count=0, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=5, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='1A1B1F', profile_background_image_url='http://abs.twimg.com/images/themes/theme9/bg.gif', profile_background_image_url_https='https://abs.twimg.com/images/themes/theme9/bg.gif', profile_background_tile=False, profile_image_url='http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', profile_image_url_https='https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', profile_link_color='2FC2EF', profile_sidebar_border_color='181A1E', profile_sidebar_fill_color='252429', profile_text_color='666666', profile_use_background_image=True, has_extended_profile=False, default_profile=False, default_profile_image=True, following=False, follow_request_sent=False, notifications=False, translator_type='none', withheld_in_countries=[])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API.get_user(screen_name='UnprotectedMe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c6caf7",
   "metadata": {},
   "source": [
    "Exploring activity/negativity relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f430021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "vectord = load('../vectord.joblib') \n",
    "model = load('../model.joblib') \n",
    "\n",
    "#tweets must be cleaned first\n",
    "def sentiment(tweets, analogue=False):\n",
    "    if analogue: \n",
    "        probs = model.predict_proba(vectord.transform(tweets).toarray())\n",
    "        return probs[:,1]-probs[:,0]\n",
    "    else: return model.predict(vectord.transform(tweets).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f673dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "erdos_core = list(pd.read_csv('erdos_full_core.csv')['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27e13c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "erdos_activities = pd.DataFrame()\n",
    "for n, user in enumerate(erdos_core):\n",
    "    try:\n",
    "        activity = get_activity(user, count=1000)\n",
    "        prep_activity(activity)\n",
    "        activity['Predicted_polarity'] = sentiment(activity.Cleaned, True)\n",
    "        activity['User'] = [user for n in range(len(activity))]\n",
    "        erdos_activities = pd.concat([erdos_activities, activity])\n",
    "    except: continue\n",
    "    if not n%10: print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb143f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "erdos_activities[['Is_retweet','Is_quote','Is_reply','Retweets','Favorites','Created','Time_since_last','Streak of 0:30:00','Streak of 6:00:00','Per 1:00:00',\"Per 1 day, 0:00:00\",'Predicted_polarity','User']].to_csv('Erdos_core_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45865141",
   "metadata": {},
   "source": [
    "Exploring followship/negativity relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a20426d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Id</th>\n",
       "      <th>Is_retweet</th>\n",
       "      <th>Is_quote</th>\n",
       "      <th>Is_reply</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Created</th>\n",
       "      <th>Cleaned</th>\n",
       "      <th>Time_since_last</th>\n",
       "      <th>Streak of 0:30:00</th>\n",
       "      <th>Streak of 6:00:00</th>\n",
       "      <th>Per 1:00:00</th>\n",
       "      <th>Per 1 day, 0:00:00</th>\n",
       "      <th>Predicted_polarity</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @AstronomerPat: @RacineSwick @WorkWithVari ...</td>\n",
       "      <td>1395210702869118982</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-20 02:52:07</td>\n",
       "      <td>rt one week data scienc lectur</td>\n",
       "      <td>2 days 12:09:26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026356</td>\n",
       "      <td>840727059001417728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dreams can come true @AstronomerPat https://t....</td>\n",
       "      <td>1394302356267880449</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-17 14:42:41</td>\n",
       "      <td>dream come true</td>\n",
       "      <td>0 days 00:00:38</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.023730</td>\n",
       "      <td>840727059001417728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@AstronomerPat @WorkWithVari Same excellent co...</td>\n",
       "      <td>1394302197006053379</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-17 14:42:03</td>\n",
       "      <td>excel content screen</td>\n",
       "      <td>10 days 14:15:05</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.911806</td>\n",
       "      <td>840727059001417728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Our May Data Science Boot Camp is in full swin...</td>\n",
       "      <td>1390463130627674113</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-05-07 00:26:58</td>\n",
       "      <td>may data scienc boot camp full swing photo credit</td>\n",
       "      <td>0 days 00:09:20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.026356</td>\n",
       "      <td>840727059001417728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@AstronomerPat @MattOsborne71: This is the mos...</td>\n",
       "      <td>1390460782647906306</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2021-05-07 00:17:38</td>\n",
       "      <td>retweet ever photo data scienc boot camp</td>\n",
       "      <td>6 days 12:42:47</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.026356</td>\n",
       "      <td>840727059001417728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18651</th>\n",
       "      <td>@AltonStandifer saw this. looking forward to t...</td>\n",
       "      <td>1312421430915665925</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-03 15:57:07</td>\n",
       "      <td>saw look forward talk also thought iron ask wa...</td>\n",
       "      <td>0 days 00:00:14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>556041652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18652</th>\n",
       "      <td>Many thanks to @karinbrulliard for including h...</td>\n",
       "      <td>1312421371130130442</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-10-03 15:56:53</td>\n",
       "      <td>mani thank includ interview towngown stori</td>\n",
       "      <td>0 days 18:09:22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.725753</td>\n",
       "      <td>556041652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18653</th>\n",
       "      <td>@Jeff_Piestrak @PezeshkiCharles @ugobardi In t...</td>\n",
       "      <td>1312147224558665728</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-02 21:47:31</td>\n",
       "      <td>famili scienc field gener substanti evid regar</td>\n",
       "      <td>0 days 03:59:29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.188250</td>\n",
       "      <td>556041652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18654</th>\n",
       "      <td>@Jeff_Piestrak @PezeshkiCharles @ugobardi I've...</td>\n",
       "      <td>1312086958248779777</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-02 17:48:02</td>\n",
       "      <td>like great deal embri work past line seem espec</td>\n",
       "      <td>0 days 01:09:22</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.212042</td>\n",
       "      <td>556041652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18655</th>\n",
       "      <td>@PezeshkiCharles Like raptors... https://t.co/...</td>\n",
       "      <td>1312069501341634561</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-02 16:38:40</td>\n",
       "      <td>like raptor</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.008599</td>\n",
       "      <td>556041652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18656 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text                   Id  \\\n",
       "0      RT @AstronomerPat: @RacineSwick @WorkWithVari ...  1395210702869118982   \n",
       "1      Dreams can come true @AstronomerPat https://t....  1394302356267880449   \n",
       "2      @AstronomerPat @WorkWithVari Same excellent co...  1394302197006053379   \n",
       "3      Our May Data Science Boot Camp is in full swin...  1390463130627674113   \n",
       "4      @AstronomerPat @MattOsborne71: This is the mos...  1390460782647906306   \n",
       "...                                                  ...                  ...   \n",
       "18651  @AltonStandifer saw this. looking forward to t...  1312421430915665925   \n",
       "18652  Many thanks to @karinbrulliard for including h...  1312421371130130442   \n",
       "18653  @Jeff_Piestrak @PezeshkiCharles @ugobardi In t...  1312147224558665728   \n",
       "18654  @Jeff_Piestrak @PezeshkiCharles @ugobardi I've...  1312086958248779777   \n",
       "18655  @PezeshkiCharles Like raptors... https://t.co/...  1312069501341634561   \n",
       "\n",
       "       Is_retweet  Is_quote  Is_reply  Retweets  Favorites  \\\n",
       "0            True     False     False         1          0   \n",
       "1           False      True     False         0          1   \n",
       "2           False     False      True         0          1   \n",
       "3           False      True     False         0          4   \n",
       "4           False     False      True         1          6   \n",
       "...           ...       ...       ...       ...        ...   \n",
       "18651       False     False      True         0          0   \n",
       "18652       False     False     False         1          3   \n",
       "18653       False     False      True         0          2   \n",
       "18654       False     False      True         0          2   \n",
       "18655       False     False      True         0          1   \n",
       "\n",
       "                  Created                                            Cleaned  \\\n",
       "0     2021-05-20 02:52:07                     rt one week data scienc lectur   \n",
       "1     2021-05-17 14:42:41                                    dream come true   \n",
       "2     2021-05-17 14:42:03                               excel content screen   \n",
       "3     2021-05-07 00:26:58  may data scienc boot camp full swing photo credit   \n",
       "4     2021-05-07 00:17:38           retweet ever photo data scienc boot camp   \n",
       "...                   ...                                                ...   \n",
       "18651 2020-10-03 15:57:07  saw look forward talk also thought iron ask wa...   \n",
       "18652 2020-10-03 15:56:53         mani thank includ interview towngown stori   \n",
       "18653 2020-10-02 21:47:31     famili scienc field gener substanti evid regar   \n",
       "18654 2020-10-02 17:48:02    like great deal embri work past line seem espec   \n",
       "18655 2020-10-02 16:38:40                                        like raptor   \n",
       "\n",
       "       Time_since_last  Streak of 0:30:00  Streak of 6:00:00  Per 1:00:00  \\\n",
       "0      2 days 12:09:26                  1                  1            1   \n",
       "1      0 days 00:00:38                  2                  2            2   \n",
       "2     10 days 14:15:05                  2                  2            2   \n",
       "3      0 days 00:09:20                  2                  2            2   \n",
       "4      6 days 12:42:47                  2                  2            2   \n",
       "...                ...                ...                ...          ...   \n",
       "18651  0 days 00:00:14                  2                  2            2   \n",
       "18652  0 days 18:09:22                  2                  2            2   \n",
       "18653  0 days 03:59:29                  1                  3            1   \n",
       "18654  0 days 01:09:22                  1                  3            1   \n",
       "18655              NaT                  1                  3            1   \n",
       "\n",
       "       Per 1 day, 0:00:00  Predicted_polarity                User  \n",
       "0                       1           -0.026356  840727059001417728  \n",
       "1                       2           -0.023730  840727059001417728  \n",
       "2                       2            0.911806  840727059001417728  \n",
       "3                       2           -0.026356  840727059001417728  \n",
       "4                       2           -0.026356  840727059001417728  \n",
       "...                   ...                 ...                 ...  \n",
       "18651                   2            0.010908           556041652  \n",
       "18652                   2            0.725753           556041652  \n",
       "18653                   3            0.188250           556041652  \n",
       "18654                   3            0.212042           556041652  \n",
       "18655                   3           -0.008599           556041652  \n",
       "\n",
       "[18656 rows x 16 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28e77a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tomi_activities = pd.read_csv('Tomi_core_tweets.csv')\n",
    "with open('Tomi_core.txt', 'r') as reader:\n",
    "    tomi_core = [int(user) for user in reader.readlines()]\n",
    "\n",
    "averages = []\n",
    "for user in tomi_core:\n",
    "    polarities = tomi_activities.Predicted_polarity[[i for i in tomi_activities.index if tomi_activities.User[i]==user]]\n",
    "    mean = (0 if len(polarities)==0 else np.mean(polarities))\n",
    "    averages.append(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad54082a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04114194694522725,\n",
       " 0.07433786263837878,\n",
       " 0.16074189954019405,\n",
       " 0.19532417971510796,\n",
       " -0.005821568789379526,\n",
       " 0.3589881429514164,\n",
       " 0.0303263620883977,\n",
       " 0.06241997161555755,\n",
       " 0.11038947990641014,\n",
       " 0.22877099623412356,\n",
       " 0.1672776981800818,\n",
       " -0.03925673271201909,\n",
       " -0.023961598843165486,\n",
       " -0.08186073376243334,\n",
       " 0.006291437858897314,\n",
       " -0.09945117382384706,\n",
       " -0.019014694255329482,\n",
       " -0.028951450990162254,\n",
       " -0.029918858552976588,\n",
       " -0.061489312511163484,\n",
       " -0.042581423800928296,\n",
       " -0.022716581244002935,\n",
       " -0.05278408387109866,\n",
       " -0.053669453525394345,\n",
       " -0.008839471434550949,\n",
       " -0.08402331021794951,\n",
       " 0.07790118762774641,\n",
       " 0.0023395298476488026,\n",
       " 0.050403777920654085,\n",
       " -0.07684738327803117,\n",
       " 0.12862584984475964,\n",
       " -0.0033051517951969817,\n",
       " 0.01658910791156576,\n",
       " 0.01997550259432464,\n",
       " 0.08591942425089485,\n",
       " -0.0830932865396215,\n",
       " 0.06783290645299621,\n",
       " 0.06502560068565374,\n",
       " -0.05011216896483873,\n",
       " 0.03351758251158142,\n",
       " 0.08840775289229379,\n",
       " -0.03686137221410989,\n",
       " 0.020718566784352868,\n",
       " -0.013924678129662544,\n",
       " -0.03425235628872195,\n",
       " -0.14230244946094112,\n",
       " 0.11410250191864339,\n",
       " 0.2237165901664443,\n",
       " 0.16670304984778525,\n",
       " 0.10304682807620508,\n",
       " 0.056056816286987665,\n",
       " -0.04250451195069867,\n",
       " -0.009255668239666934,\n",
       " -0.09683700352262867,\n",
       " 0.3041394401371668,\n",
       " 0.08320279375615025,\n",
       " 0.18629582284744559,\n",
       " 0.10464335090986293,\n",
       " 0.09230057257557205,\n",
       " 0.15562901992046566,\n",
       " 0.05826668895392407,\n",
       " 0.1124479831281543,\n",
       " 0.02433899219070232,\n",
       " 0.2746267628212435,\n",
       " 0.2311905408371077,\n",
       " 0.13106395862881245,\n",
       " 0.4460064861262251,\n",
       " 0.07743514742863984,\n",
       " 0.19883150561064653,\n",
       " -0.0194734115444364,\n",
       " 0.21009414666049533,\n",
       " 0.19402911167883363,\n",
       " -0.023050956706618077,\n",
       " 0.5215856424542085,\n",
       " 0.012593531016588666,\n",
       " 0.16513067158934874,\n",
       " 0.26594473364072324,\n",
       " 0.26767929060571516,\n",
       " -0.5582007161039966,\n",
       " 0.009090160594655278,\n",
       " 0.055950060209371516,\n",
       " 0.013199478005179954,\n",
       " 0.14962687339823996,\n",
       " 0.06305338024345136,\n",
       " 0.014993627249936796,\n",
       " 0.054752247080296926,\n",
       " 0.008770618424349806,\n",
       " 0.006405818255542457,\n",
       " 0.08978418577233721,\n",
       " -0.050734718129049346,\n",
       " -0.008942664680748627,\n",
       " -0.024347476544291903,\n",
       " 0.03727877316095812,\n",
       " -0.07218466482727245,\n",
       " -0.05621644061186437,\n",
       " -0.11342039315769387,\n",
       " 0.032134634924779026,\n",
       " 0.038900197702873646,\n",
       " 0.3272158804505097,\n",
       " 0.10081270130636717,\n",
       " -0.055295761755658826,\n",
       " 0.18750860929986876,\n",
       " 0.1256267435444382,\n",
       " -0.01634341506002591,\n",
       " 0.19610725990621802,\n",
       " 0.20253640356105893,\n",
       " 0.012956194449900474,\n",
       " 0.09156383978275051,\n",
       " 0.14564752953881654,\n",
       " 0.06126962364288486,\n",
       " 0.10306418933015418]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a0d44dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tomi_cross_core = pd.read_csv('Tomi_cross_core.csv')\n",
    "tomi_cross_core['Average_polarity'] = averages\n",
    "tomi_cross_core.to_csv('Tomi_cross_core.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c461e67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User(_api=<tweepy.api.API object at 0x000001AACC353BC8>, _json={'id': 2665748041, 'id_str': '2665748041', 'name': 'Rosanna Landis Weaver', 'screen_name': 'LandisWeaver', 'location': '', 'profile_location': None, 'description': 'I write reports on overpaid CEOs & how funds vote on pay. I read everything I can. I tweet social justice, corporate governance, books, gardens, adoption, kids', 'url': 'https://t.co/TbT3jqonCd', 'entities': {'url': {'urls': [{'url': 'https://t.co/TbT3jqonCd', 'expanded_url': 'https://www.asyousow.org/our-work/ceo-pay', 'display_url': 'asyousow.org/our-work/ceo-p…', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 5310, 'friends_count': 4012, 'listed_count': 99, 'created_at': 'Mon Jul 21 12:05:53 +0000 2014', 'favourites_count': 126820, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 36177, 'lang': None, 'status': {'created_at': 'Fri May 28 18:00:44 +0000 2021', 'id': 1398338465205477387, 'id_str': '1398338465205477387', 'text': \"@Tvbona That's not really a defense.\", 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'Tvbona', 'name': 'Thomas V. Bona', 'id': 14752005, 'id_str': '14752005', 'indices': [0, 7]}], 'urls': []}, 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>', 'in_reply_to_status_id': 1398337965751996422, 'in_reply_to_status_id_str': '1398337965751996422', 'in_reply_to_user_id': 14752005, 'in_reply_to_user_id_str': '14752005', 'in_reply_to_screen_name': 'Tvbona', 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'C0DEED', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/491201168337403905/gYz7IcdG_normal.jpeg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/491201168337403905/gYz7IcdG_normal.jpeg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/2665748041/1546197127', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, id=2665748041, id_str='2665748041', name='Rosanna Landis Weaver', screen_name='LandisWeaver', location='', profile_location=None, description='I write reports on overpaid CEOs & how funds vote on pay. I read everything I can. I tweet social justice, corporate governance, books, gardens, adoption, kids', url='https://t.co/TbT3jqonCd', entities={'url': {'urls': [{'url': 'https://t.co/TbT3jqonCd', 'expanded_url': 'https://www.asyousow.org/our-work/ceo-pay', 'display_url': 'asyousow.org/our-work/ceo-p…', 'indices': [0, 23]}]}, 'description': {'urls': []}}, protected=False, followers_count=5310, friends_count=4012, listed_count=99, created_at=datetime.datetime(2014, 7, 21, 12, 5, 53), favourites_count=126820, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=36177, lang=None, status=Status(_api=<tweepy.api.API object at 0x000001AACC353BC8>, _json={'created_at': 'Fri May 28 18:00:44 +0000 2021', 'id': 1398338465205477387, 'id_str': '1398338465205477387', 'text': \"@Tvbona That's not really a defense.\", 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'Tvbona', 'name': 'Thomas V. Bona', 'id': 14752005, 'id_str': '14752005', 'indices': [0, 7]}], 'urls': []}, 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>', 'in_reply_to_status_id': 1398337965751996422, 'in_reply_to_status_id_str': '1398337965751996422', 'in_reply_to_user_id': 14752005, 'in_reply_to_user_id_str': '14752005', 'in_reply_to_screen_name': 'Tvbona', 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, created_at=datetime.datetime(2021, 5, 28, 18, 0, 44), id=1398338465205477387, id_str='1398338465205477387', text=\"@Tvbona That's not really a defense.\", truncated=False, entities={'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'Tvbona', 'name': 'Thomas V. Bona', 'id': 14752005, 'id_str': '14752005', 'indices': [0, 7]}], 'urls': []}, source='Twitter Web App', source_url='https://mobile.twitter.com', in_reply_to_status_id=1398337965751996422, in_reply_to_status_id_str='1398337965751996422', in_reply_to_user_id=14752005, in_reply_to_user_id_str='14752005', in_reply_to_screen_name='Tvbona', geo=None, coordinates=None, place=None, contributors=None, is_quote_status=False, retweet_count=0, favorite_count=0, favorited=False, retweeted=False, lang='en'), contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='C0DEED', profile_background_image_url='http://abs.twimg.com/images/themes/theme1/bg.png', profile_background_image_url_https='https://abs.twimg.com/images/themes/theme1/bg.png', profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/491201168337403905/gYz7IcdG_normal.jpeg', profile_image_url_https='https://pbs.twimg.com/profile_images/491201168337403905/gYz7IcdG_normal.jpeg', profile_banner_url='https://pbs.twimg.com/profile_banners/2665748041/1546197127', profile_link_color='1DA1F2', profile_sidebar_border_color='C0DEED', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=True, default_profile=True, default_profile_image=False, following=False, follow_request_sent=False, notifications=False, translator_type='none', withheld_in_countries=[])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454e67d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
