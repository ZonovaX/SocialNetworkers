{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e3b3674",
   "metadata": {},
   "source": [
    "# Use this on a Twitter account to find bad eggs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f07c0e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b752a5b5",
   "metadata": {},
   "source": [
    "### Import these packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88da72fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tweepy\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35605da3",
   "metadata": {},
   "source": [
    "### Choose your parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40dfb6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Screen name of network's center\n",
    "center = 'erdosinstitute'\n",
    "# Name to save files to\n",
    "name = 'Test'\n",
    "# Number of mutuals to find\n",
    "breadth = 2\n",
    "# Number of times to find them\n",
    "depth = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec9b1b4",
   "metadata": {},
   "source": [
    "### Choose your senitment analyzer. For example here we use Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "579edc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Ysgard\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Necessary parts of the analyzer\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# The analyzer itself\n",
    "def analyzer(tweet):\n",
    "    return SentimentIntensityAnalyzer().polarity_scores(tweet)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebfb87c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We could also use this\n",
    "#from joblib import load\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "#import string\n",
    "#from nltk.stem import PorterStemmer\n",
    "#import re\n",
    "#\n",
    "#stop_words=stopwords.words('english')\n",
    "#punct=string.punctuation\n",
    "#stemmer=PorterStemmer()\n",
    "#\n",
    "#vectord = load('vectord.joblib') \n",
    "#model = load('model.joblib') \n",
    "#\n",
    "##tweets must be cleaned first\n",
    "#def analyzer(tweets, analogue=False):\n",
    "#    #clean the text\n",
    "#    cleets = []\n",
    "#    for twittre in activity.Text:\n",
    "#        #this removes mentions\n",
    "#        twittre = re.sub(r'@[A-Za-z0-9_]+', '', twittre)\n",
    "#        #this removes urls\n",
    "#        twittre = re.sub(r'https?:\\/\\/[A-Za-z0-9\\.\\/]+', '', twittre)        \n",
    "#        #this removes everything but letters from the str\n",
    "#        twittre = re.sub('[^a-zA-Z]',' ',twittre)\n",
    "#        #this makes everything lowercase, then turns everything that is separated by a space into its own str\n",
    "#        twittre = twittre.lower().split()\n",
    "#        #this removes stop words and stems everything else\n",
    "#        twittre = [stemmer.stem(word) for word in twittre if (word not in stop_words)]\n",
    "#        # this puts it all back together with spaces inbetween\n",
    "#        twittre = ' '.join(twittre)\n",
    "#        cleets.append(twittre)\n",
    "#    activity['Cleaned'] = cleets\n",
    "#\n",
    "#    probs = model.predict_proba(vectord.transform(tweets).toarray())\n",
    "#    return probs[:,1]-probs[:,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e264d14",
   "metadata": {},
   "source": [
    "### You'll need a Twitter developer account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "279ad203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your credentials\n",
    "API_key = ''\n",
    "API_secret_key = ''\n",
    "access_token = ''\n",
    "access_token_secret = ''\n",
    "\n",
    "# Connect to the API\n",
    "authenticator = tweepy.OAuthHandler(API_key, API_secret_key)\n",
    "authenticator.set_access_token(access_token, access_token_secret)\n",
    "API = tweepy.API(authenticator, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1a8d6f",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3998084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(user, breadth=10, depth=2, network=[], save=False):\n",
    "    #type user as a screen name so this works\n",
    "    howrite = 'a'\n",
    "    \n",
    "    # Make sure we're finding the right user\n",
    "    if type(user)==str:\n",
    "        user = API.get_user(screen_name=user).id\n",
    "        howrite = 'w'\n",
    "    elif type(user)!=int:\n",
    "        raise Exception(\"Bad user.\")\n",
    "    \n",
    "    #make sure we have good data\n",
    "    try:\n",
    "        friends = API.friends_ids(user_id=user)\n",
    "        friends[0]\n",
    "    except: \n",
    "        return False\n",
    "    \n",
    "    #one list for user's mutuals, one list for everyone\n",
    "    mutuals = []\n",
    "    network.append(user)\n",
    "    if save:\n",
    "        try:\n",
    "            with open(save, howrite) as save_file:\n",
    "                save_file.write(str(user)+'\\n')\n",
    "        except: \n",
    "            raise Exception('Bad save file')\n",
    "    \n",
    "    #we won't delve too deep or too greedily\n",
    "    if depth:\n",
    "        #find random friends of user who follow user back (mutuals)\n",
    "        for friend in np.random.permutation(friends):\n",
    "            friend = int(friend)\n",
    "            if friend not in network:\n",
    "                if API.show_friendship(source_id=friend, target_id=user)[0].following:\n",
    "                    #find their mutuals, but only add them to the list if it's good data\n",
    "                    if build_network(friend, breadth=breadth, depth=depth-1, network=network, save=save):\n",
    "                        #add them to the list\n",
    "                        mutuals.append(friend)\n",
    "                    #but only some of them\n",
    "                    if len(mutuals)==breadth:\n",
    "                        print(friend,'has mutuals',mutuals)\n",
    "                        break\n",
    "    \n",
    "    #and here's the list\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb5242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity(user, count=200,\n",
    "                 streak_lengths=[datetime.timedelta(minutes=30),datetime.timedelta(hours=6)], \n",
    "                 per_periods=[datetime.timedelta(hours=1),datetime.timedelta(days=1)], save=False):\n",
    "    # Make sure we're finding the right user\n",
    "    if type(user)==str:\n",
    "        apitivity = API.user_timeline(screen_name=user, count=count)\n",
    "    elif type(user)==int:\n",
    "        apitivity = API.user_timeline(user_id=user, count=count)\n",
    "    else:\n",
    "        raise Exception(\"Bad user.\") \n",
    "        \n",
    "    # Make a list of the statuses\n",
    "    activiray = []\n",
    "    #and add the relevant data\n",
    "    for tweet in apitivity:\n",
    "        try: \n",
    "            tweet.retweeted_status\n",
    "            is_retweet = True\n",
    "        except: \n",
    "            is_retweet = False\n",
    "        activiray.append([tweet.text,\n",
    "                         tweet.id,\n",
    "                         is_retweet,\n",
    "                         tweet.is_quote_status,\n",
    "                         type(tweet.in_reply_to_status_id)==int,\n",
    "                         tweet.retweet_count,\n",
    "                         tweet.favorite_count,\n",
    "                         tweet.created_at])\n",
    "        \n",
    "    # turn it into a dataframe\n",
    "    activity = pd.DataFrame(activiray, \n",
    "                            columns=['Text', 'Id', 'Is_retweet', 'Is_quote', 'Is_reply', 'Retweets', 'Favorites', 'Created'])\n",
    "    \n",
    "    # record the time since the last status update\n",
    "    tsl = [activity.Created[n].to_pydatetime() - activity.Created[n+1].to_pydatetime()\n",
    "                                   for n in range(len(activity)-1)] + [np.nan]\n",
    "    activity['Time_since_last'] = tsl.copy()\n",
    "    \n",
    "    #record how many times in a row the last activity was less than length \n",
    "    for length in streak_lengths:\n",
    "        #record when it was less than length\n",
    "        streak_break = [time>length for time in tsl[:-1]]+[True]\n",
    "        \n",
    "        #intialize beginning of a streak\n",
    "        start = 0\n",
    "        streak = []\n",
    "        for end in range(len(streak_break)):\n",
    "            #if this is the end of a streak,  \n",
    "            if streak_break[end]:\n",
    "                #record it,\n",
    "                streak += [end+1-start for indx in range(end+1-start)]\n",
    "                #and begin the next\n",
    "                start = end+1\n",
    "        \n",
    "        #finally, add it to the data frame\n",
    "        activity['Streak of '+str(length)] = streak\n",
    "        \n",
    "    #record how much activity occured within a given period \n",
    "    for period in per_periods:\n",
    "        per = []\n",
    "        for n in range(len(tsl)):\n",
    "            elapsed = tsl[n]\n",
    "            count, m = 0, 1\n",
    "            #first we look at earlier tweets\n",
    "            while (m+n<len(tsl)) and (elapsed<=period/2):\n",
    "                count += 1\n",
    "                try: elapsed += tsl[m+n]\n",
    "                except: pass\n",
    "                m += 1\n",
    "            m = 0\n",
    "            elapsed = datetime.timedelta(0)\n",
    "            #then later tweets\n",
    "            while n>=m and elapsed<=period/2:\n",
    "                count += 1\n",
    "                m += 1\n",
    "                try: elapsed += tsl[n-m]\n",
    "                except: pass\n",
    "            per += [count]\n",
    "        activity['Per '+str(period)] = per\n",
    "        \n",
    "    if save:\n",
    "        activity.to_json(save, index=False)\n",
    "        \n",
    "    return activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f8524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_activities(network , save=False):\n",
    "    #initialize the dataframe\n",
    "    activities = pd.DataFrame()\n",
    "    \n",
    "    #concatenate each \n",
    "    for n, user in enumerate(network):\n",
    "        try:\n",
    "            activity = get_activity(user, count=1000)\n",
    "            prep_activity(activity)\n",
    "            activity['Predicted_polarity'] = sentiment(activity.Cleaned, True)\n",
    "            activity['User'] = [user for n in range(len(activity))]\n",
    "            activities = pd.concat([activities, activity])\n",
    "        except: continue\n",
    "        if not n%10: print(n)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2120fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_data(core, crust, data=[], save=False, restart=0):\n",
    "    #we assign core members as features\n",
    "    columns = ['core_'+str(n) for n in range(len(core))]\n",
    "    if save and not restart: \n",
    "        with open(save, 'r') as save_file:\n",
    "            text = [''] + save_file.readlines()\n",
    "        for column in columns:\n",
    "            text[0] += ',' + str(column)\n",
    "        text[0] += '\\n'\n",
    "        with open(save, 'w+') as save_file:\n",
    "            save_file.writelines(text)\n",
    "        \n",
    "    #now we see which crust members are following which core members\n",
    "    for n, crust_member in [x for x in enumerate(crust) if x[0]>=restart]:\n",
    "        #this will hold what we find\n",
    "        next_line = []\n",
    "        #look up who the crust member is following\n",
    "        following, pages = API.friends_ids(user_id=crust_member, cursor=-1)\n",
    "        \n",
    "        for core_member in core:\n",
    "            #page through if necessary\n",
    "            while pages[1] and (core_member not in following):\n",
    "                more_following, pages = API.friends_ids(user_id=crust_member, cursor=pages[1])\n",
    "                following += more_following\n",
    "            next_line.append(core_member in following)\n",
    "        \n",
    "        #We'll say people follow themselves\n",
    "        if n < len(core):\n",
    "            next_line[n]==True\n",
    "        \n",
    "        #now we store it\n",
    "        data.append(next_line)\n",
    "        if save: \n",
    "            with open(save, 'r') as save_file:\n",
    "                text = save_file.readlines()\n",
    "            text[n+1] = text[n+1][:-1]\n",
    "            for datum in next_line:\n",
    "                text[n+1] += ',' + str(datum)\n",
    "            text[n+1] += '\\n'\n",
    "            with open(save, 'w') as save_file:\n",
    "                save_file.writelines(text)\n",
    "        print('Stored data for member', n+1, 'of', len(crust))\n",
    "    \n",
    "    #and finally put it all together\n",
    "    return pd.DataFrame(data, index=crust, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bb8e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e05bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
